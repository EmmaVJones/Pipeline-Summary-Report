---
title: "Monitoring System Functions"
output:
  html_document: 
     code_folding: "hide"
  html_notebook: 
     code_folding: "hide"
---

This notebook details functions written for analysis of continuous monitoring water quality data from paired United States Geological Survey (USGS) stream gages. The functions are detailed in this Rnotebook to allow for any user to understand the analyses. To best utilize these scripts, one should convert the .Rmd  to a .R to be sourced into a script and run either manually or automatically with a cronjob.

<hr>

## Flag Overview

The following sections briefly explain flags generated by the analysis functions laid out in detail in the Detailed Process Summary section. Additional questions on calculations not answered by the Detailed Process Summary sections should be directed to Emma Jones (emma.jones@deq.virginia.gov), Jason Hill (jason.hill@deq.virginia.gov), and Andrew Garey (andrew.garey@deq.virginia.gov).

### Temperature

Notifications that appear in the Parameter Notification table when either of the below conditions occur in 10% or more of cases over the analyzed time window:

1. Instantaneous measures at a site measure above the site specific WQS criteria. See the WQS_Class field on the Gage-Specific Thresholds table.
    + T_upstreamMaxFlag
    + T_downstreamMaxFlag
2. Hourly change rates at a site measure above the site specific WQS criteria. See the WQS_Class field on the Gage-Specific Thresholds table.
    + T_upstreamHourlyChangeFlag
    + T_downstreamHourlyChangeFlag
3. Upstream/downstream measures for a gage pair differ by more than 1 degree Celsius in class VI waters or 3 degrees Celsius in class III, IV, or V waters.
    + T_riseAboveNaturalFlag
    
### Dissolved Oxygen

Notifications that appear in the Parameter Notification table when either of the below conditions occur in 10% or more of cases over the analyzed time window:

1. Instantaneous measures at a site measure below the site specific WQS criteria. See the WQS_Class field on the Gage-Specific Thresholds table.
    + DO_upstreamMinFlag
    + DO_downstreamMinFlag
2. Upstream/downstream measures for a gage pair differ by 1 mg/L or more.
    + DO_upDownDifferenceFlag
3. Upstream/downstream measures for a gage pair differ by 20% or more in systems lower conductivity (SpCond_Designation = 200 uS/cm). This flag is ignored in high conductivity designated systems (SpCond_Designation = 500 uS/cm).
    + spCond_upDownPercentDifferenceFlag

### pH

Notifications that appear in the Parameter Notification table when either of the below conditions occur in 10% or more of cases over the analyzed time window:

1. Instantaneous measures at a site vary outside site specific WQS criteria. See the WQS_Special and pH_SpecialStandards fields on the Gage-Specific Thresholds table.
    + pH_upstreamFlag
    + pH_downstreamFlag
2. Upstream/downstream measures for a gage pair differ by more than the value listed in pH-RangeAllowance field in the Gage-Specific Thresholds table.
    + pH_upDownDifferenceFlag


### Specific Conductance

Notifications that appear in the Parameter Notification table when either of the below conditions occur in 10% or more of cases over the analyzed time window:

1. Instantaneous measures at a site exceed the values listed on the Gage-Specific Thresholds table (see SpCond_Designation field)
    + spCond_upstreamFlag
    + spCond_downstreamFlag
2. Upstream/downstream measures for a gage pair differ by 50 uS/cm or more in systems lower conductivity (SpCond_Designation = 200 uS/cm) or gage pairs differ by 100 uS/cm in high conductivity designated systems (SpCond_Designation = 500 uS/cm).
    + spCond_upDownNumericDifferenceFlag
3. Upstream/downstream measures for a gage pair differ by 20% or more in systems lower conductivity (SpCond_Designation = 200 uS/cm). This flag is ignored in high conductivity designated systems (SpCond_Designation = 500 uS/cm).
    + spCond_upDownPercentDifferenceFlag


### Turbidity

Notifications that appear in the Parameter Notification table when either of the below conditions occur in 10% or more of cases over the analyzed time window:

* Rolling 30 minute windows of data measures above a baseline turbidity measure. Baseline turbidity levels are calculated by taking the maximum of the median upstream turbidity and median downstream turbidity measures over the analyzed data window.

1. Where baseline turbidity level are less than or equal to 40 FNU, numeric differences are utilized. Downstream turbidity measures of 6 FNU or greater maintained for 30 minutes or more compared to the appropriate upstream gage trigger flags. 
    + turbidity_upDownNumericFlag
2. Where baseline turbidity level are greater than 40 FNU, percent differences are utilized. Downstream turbidity measures of 15% or greater maintained for 30 minutes or more compared to the appropriate upstream gage trigger flags. 
    + turbidity_upDownPercentFlag
3. Individual gages are compared to their unique 99th percentile criteria. These percentiles are calculated from each background gage dataset from installation date in 2017 to February 2018 (i.e. prior to any construction activities). Measures above a given 99th percentile maintained for at least 30 minutes generate flags.
    + turbidity_upstreamFlag99th
    + turbidity_downstreamFlag99th



<hr>

## Detailed Process Summary

The following sections lay out full methods for pulling gage data and generating flags for each of the below parameters.

### Retrieve  Data
Pull water quality data from National Water Information System (NWIS) server with custom date range and automatic conversion of field names to a more understandable format.

```{r}
NWISpull <- function(gageNo,start,end){
  allUnitData <- readNWISuv(siteNumbers=gageNo,
                            parameterCd=c("00010", "00095", "00300", "00400", "63680","00065"),
                            startDate=as.Date(start,"%Y-%m-%d"),
                            endDate=as.Date(end,"%Y-%m-%d"),
                            tz='America/New_York')
  allUnitData <- renameNWISColumns(allUnitData)
}
```

### Criteria Flags

These functions are used within other functions to significantly reduce the amount of code required to do said analyses.

Compare data to a numeric criteria.

```{r}
numericThreshold <- function(x, threshold){
  suppressWarnings(
    if(min(x,na.rm=T)==Inf){NA
    }else{ifelse(min(x,na.rm=T)>threshold,1,0) })}
```

Compare data to a percentage criteria.
```{r}
percentThreshold <- function(x,threshold){  
  suppressWarnings(
    if(min(x,na.rm=T)==Inf){NA
    }else{ifelse(min(x,na.rm=T)>threshold,1,0)  })}
```

Count number of NA's.
```{r}
NArecords <- function(x){
  sum(is.na(x))
}
```

Temperature and turbidity require their own numeric and percentage (in the case of turbidity) criteria flags to efficiently output multiple results from rolling windows when applied to the tidyquant::tq_mutate function.

Compare maximum and minimum temperature data to numeric criteria, and output associated NA's. This function is applied to a window of data to find the maximum hourly change according to 9VAC25-260-70.

```{r}
temperatureHourlyChange <- function(x,threshold){
  Tchange <- max(x, na.rm=T)-min(x, na.rm=T)
  NAs <- NArecords(x)
  flag <- ifelse(Tchange>threshold,1,0)
  z <- c(T_maxHourlyChange=Tchange, T_hourlyChangeFlag=flag,T_NAs=NAs)
  return(z)
}
```


Compare turbidity data to numeric criteria and output associated NA's.
```{r}
turbidityNumericFlag <- function(x,threshold){
  exceed <- numericThreshold(x,threshold)
  NAs <- NArecords(x)
  z <- c(turbidity_Flag=exceed,turbidity_NAs=NAs)
  return(z)
}
```

Compare turbidity data to percentage criteria and output associated NA's.
```{r}
turbidityPercentFlag <- function(x,threshold){
  exceed <- numericThreshold(x,threshold)
  NAs <- NArecords(x)
  z <- c(turbidity_Flag=exceed,turbidity_NAs=NAs)
  return(z)
}
```

### Parameter Specific Functions
These next functions complete the analyses for each of the parameters pulled from the NWIS  server. The functions have specific rules within them to handle missing data (NA's), data out of a normal range (probe malfunctions), and data transmission failures.

#### Temperature
temperatureByWQSclass() is a helper function that operates inside of the temperature function. Henceforth, whenever describing a named function, the name of the function will be followed by () signify it is a function, e.g. temperature(). The temperatureByWQSclass() takes a dataset manipulated within the temperature() and applies specific water  quality standard (WQS) class criteria to on an hourly window of data to identify windows that are outside of the criteria set by WQS class. The temperature() replaces data that are outside of the normal expected  range for a temperature sensor in freshwater (0-40 Celsius) to avoid probe malfunctions from skewing analyses. If the input dataset (after replacement) does not meet the minimum 1 hour window criteria, it is not analyzed for the maximum change within 1 hour rule. The rolling window calculations are applied to the upstream and downstream gage datasets separately such that if one gage does not meet the hour window criteria, the other gage can still be analyzed. Data output in the T_upstreamHourlyChangeFlag/T_downstreamHourlyChangeFlag and T_upstreamNAs/T_downstreamNAs columns represent the results from each of the hour rolling window analyses, not for the entire dataset. This method allows users to verify if enough valid data was retrieved within an hour to interpret the result accurately. 

```{r}
# Temperature Analysis
temperatureByWQSclass <- function(x, maxHourlyTchange1, maxHourlyTchange2){
  # 9VAC25-260-70. Maximum Hourly Temperature Change, UPSTREAM
  if(nrow(filter(x,!is.na(upstream))) < 13){
    x <- mutate(x,T_maxHourlyChange=NA,T_hourlyChangeFlag=NA,T_NAs=NA)
  }else{x <- tq_mutate(x,
                       select     = upstream,
                       mutate_fun = rollapply, 
                       # rollapply args
                       width      = 13,
                       align      = "right",
                       by.column  = FALSE,
                       FUN        = temperatureHourlyChange,
                       # FUN args
                       threshold  = maxHourlyTchange1)}
  # 9VAC25-260-70. Maximum Hourly Temperature Change, DOWNSTREAM  
  if(nrow(filter(x,!is.na(downstream))) < 13){
    x <- mutate(x,T_maxHourlyChange..1=NA,T_hourlyChangeFlag..1=NA,T_NAs..1=NA)
  }else{x <- tq_mutate(x,
                       select     = downstream,
                       mutate_fun = rollapply, 
                       # rollapply args
                       width      = 13,
                       align      = "right",
                       by.column  = FALSE,
                       FUN        = temperatureHourlyChange,
                       # FUN args
                       threshold  = maxHourlyTchange2)}
  x <- rename(x, T_upstreamHourlyChangeFlag= T_hourlyChangeFlag, T_upstreamNAs= T_NAs,	
              T_downstreamHourlyChangeFlag= T_hourlyChangeFlag..1, T_downstreamNAs=T_NAs..1)	
  # for < R version 3.6.0
  #x <- rename(x, T_upstreamHourlyChangeFlag= T_hourlyChangeFlag, T_upstreamNAs= T_NAs,	
  #            T_downstreamHourlyChangeFlag= T_hourlyChangeFlag.1, T_downstreamNAs=T_NAs.1)	
return(x)
}
```

The temperature() is the function that takes raw temperature data and outputs flags based on WQS  class criteria. First, the function ensures water temperature data (Wtemp_Inst) was retrieved from each gage. If a gage has not recorded temperature data within the data window, the temperature fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed.

Based  on the WQS class that applies to the stream segment that the gage  is located on, the function establishes criteria to test the data against for maximum temperature, natural temperature change, and maximum hourly temperature change. Natural temperature change is the difference allowed between upstream and downstream gage pairs. All WQS class criteria applied are from 9VAC25-260-50 and 9VAC25-260-60. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage), the upstream/downstream numeric and percent difference is calculated. Percent difference is only there for visual analysis, it is  not used for any flagging of data. The T_valid1hrWindow  is the amount of time captured by lagging the data by 12 rows (i.e. calculating the amount of time the tq_mutate() will be rolling over). **Rolling windows across time series data is very  difficult** Due to computational limitations, we assume the dataset is complete, meaning data was transmitted for every 5 minute interval within the hour. This assumption is critical to efficiently run any time series analysis scripts. **If data is missing within the hour**, T_valid1hrWindow will report a number higher than 60 (60 would be expected for a valid hour window). Given how the tq_mutate() is programmed, one would never expect a number less than 60. One should not disregard data with T_valid1hrWindow close to an exact hour, it still contains valuable information. T_upstreamNAs/T_downstreamNAs record how many NA's are within the window. Later QA steps do not pass along notifications for windows that have too many NA's. More on those QA steps later. 
```{r}
temperature <- function(upstreamData, downstreamData, parameter, WQclassGage1, WQclassGage2){
  # Add Wtemp fields if no Wtemp data retrieved from probes, populate with NA 
  if(unique(c('Wtemp_Inst',"Wtemp_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('Wtemp_Inst',"Wtemp_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  # Establish thresholds based on WQS for max Temperature flags
  if(WQclassGage1==6){maxT1 <- 20; natTchange <- 1; maxHourlyTchange1 <- 0.5}
  if(WQclassGage2==6){maxT2 <- 20; natTchange <- 1; maxHourlyTchange2 <- 0.5}
  if(WQclassGage1==5){maxT1 <- 21; natTchange <- 3; maxHourlyTchange1 <- 2}
  if(WQclassGage2==5){maxT2 <- 21; natTchange <- 3; maxHourlyTchange2 <- 2}
  if(WQclassGage1==4){maxT1 <- 31; natTchange <- 3; maxHourlyTchange1 <- 2}
  if(WQclassGage2==4){maxT2 <- 31; natTchange <- 3; maxHourlyTchange2 <- 2}
  if(WQclassGage1==3){maxT1 <- 32; natTchange <- 3; maxHourlyTchange1 <- 2}
  if(WQclassGage2==3){maxT2 <- 32; natTchange <- 3; maxHourlyTchange2 <- 2}
  # natTchange called same parameter name bc want the larger # to override smaller 
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime'))%>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0 | upstream > 40, NA ),
              downstream = replace(downstream, downstream < 0 | downstream > 40, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream,
           pctDiff=(numericDiff/downstream)*100,
           window= lag(dateTime,12),
           T_valid1hrWindow=as.double(dateTime-lag(dateTime,12),units='mins'), # lag 12 bc lag already grabs 1 row above
           T_upstreamMaxFlag=ifelse(upstream>maxT1,1,0),# 9VAC25-260-50. Numerical Criteria for Maximum Temperature
           T_downstreamMaxFlag=ifelse(downstream>maxT2,1,0), # 9VAC25-260-50. Numerical Criteria for Maximum Temperature
           T_riseAboveNaturalFlag=ifelse(numericDiff>natTchange,1,0)) # 9VAC25-260-60. Rise Above Natural Temperature
    
  temperatureByWQSclass(together, maxHourlyTchange1, maxHourlyTchange2)%>%
    mutate(WQSapplied=ifelse(WQclassGage1==WQclassGage2,WQclassGage1,paste(WQclassGage1,";",WQclassGage2,sep="")))
}
```


#### Dissolved Oxygen
dissolvedOxygenByWQSclass() is a helper function that operates inside dissolvedOxygen(). The function takes minimum dissolved oxygen values, established within dissolvedOxygen() using the WQS class for each gage and adhering to 9VAC25-260-50, and flags data that is below the criteria in DO_upstreamMinFlag/DO_downstreamMinFlag. Additionally, DO_upDownDifferenceFlag flags any sites where there is greater than 1 mg/L difference between the gages.

```{r}
dissolvedOxygenByWQSclass <- function(x,minDO1,minDO2){
  together <- mutate(x,DO_upstreamMinFlag=ifelse(upstream<minDO1,1,0), # 9VAC25-260-50. Numerical Criteria for Dissolved Oxygen
                     DO_downstreamMinFlag=ifelse(downstream<minDO2,1,0),  # 9VAC25-260-50. Numerical Criteria for Dissolved Oxygen
                     DO_upDownDifferenceFlag = ifelse(abs(numericDiff)>1,1,0)) # Flag if upstream/downstream difference > 1 mg/L
  return(together)
}

```

The dissolvedOxygen() analyzes raw data against the appropriate WQS class minimum dissolved oxygen criteria for each gage. The function ensures dissolved oxygen data (DO_Inst) was retrieved from each gage. If a gage has not recorded dissolved oxygen data within the data window, the dissolved oxygen fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed.

Based on the WQS class that applies to the stream segment that the gage is located on, the function links appropriate criteria to test the data against for minimum dissolved oxygen and maximum change between upstream and downstream gage pairs. The dissolvedOxygen() replaces data that is outside of the normal expected range for a dissolved oxygen sensor in freshwater (0-25 mg/L) to avoid probe malfunctions from skewing analyses. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage), the upstream/downstream numeric and percent difference is calculated. Percent difference is only there for visual analysis, it is  not used for any flagging of data. Lastly, the dissolvedOxygenByWQSclass() uses the minimum dissolved oxygen values established from the appropriate WQS class and performs analyses, flagging dissolved oxygen values below the WQS and noting upstream/downstream differences.

```{r}
dissolvedOxygen <- function(upstreamData, downstreamData, parameter, WQclassGage1, WQclassGage2){
  # Add DO_Inst fields if no DO_Inst data retrieved from probes, populate with NA 
  if(unique(c('DO_Inst',"DO_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('DO_Inst',"DO_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  # Establish thresholds based on WQS for min DO flags
  if(WQclassGage1==6){minDO1 <- 8}
  if(WQclassGage2==6){minDO2 <- 8}
  if(WQclassGage1 %in% c(3,4,5)){minDO1 <- 7}
  if(WQclassGage2 %in% c(3,4,5)){minDO2 <- 7}
  
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime')) %>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0 | upstream > 25, NA ),
           downstream = replace(downstream, downstream < 0 | downstream > 25, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream,
           pctDiff=(numericDiff/downstream)*100)
  
  dissolvedOxygenByWQSclass(together,minDO1,minDO2)%>%
    mutate(WQSapplied=ifelse(WQclassGage1==WQclassGage2,WQclassGage1,paste(WQclassGage1,";",WQclassGage2,sep="")))
}
```

#### pH
pHbyWQS() is a helper function that operates inside pH(). The pHbyWQS() takes a dataset manipulated within pH() and applies the approprate WQS according to 9VAC25-260-50 and any special WQS criteria where applicable. Data output in the pH_upstreamFlag/pH_downstreamFlag columns flag any pH values outside of the WQS criteria for that gage. The pH_upDownDifferenceFlag columns represents the results from comparing the two gages and flags any pairs of measures that fall outside of the pH range for the gage pairs. The Cowpasture is the only gage pair at present that has a pH range allowance above 0.5 standard units due to known natural spring inputs that alter pH between the gages.

```{r}
pHbyWQS <- function(x,pHspecialStandards,pHrangeAllowance){
  # Adjust standards if WQS special standard for site
  min_pH <- ifelse(pHspecialStandards=="Y",6.5,6)
  max_pH <- ifelse(pHspecialStandards=="Y",9.5,9)
  
  together <- mutate(x,pH_upstreamFlag=ifelse(upstream > min_pH & upstream < max_pH,0,1), # 9VAC25-260-50. Numerical Criteria for pH
                     pH_downstreamFlag=ifelse(downstream > min_pH & downstream < max_pH,0,1),  # 9VAC25-260-50. Numerical Criteria for pH
                     pH_upDownDifferenceFlag = ifelse(abs(numericDiff)>pHrangeAllowance,1,0)) # Flag if upstream/downstream difference > allowed range
  return(together)
}
```

The pH() performs QA and manipulation prior to applying pHbyWQS() to analyze data against the appropriate WQS. The function ensures pH data (pH_Inst) was retrieved from each gage. If a gage has not recorded pH data within the data window, the pH fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed.

The pH() replaces data that is outside of the normal expected range for a pH sensor in freshwater (0-14 standard units) to avoid probe malfunctions from skewing analyses. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage), the upstream/downstream numeric and percent difference is calculated. Percent difference is only there for visual analysis, it is  not used for any flagging of data. Lastly, the pHbyWQS() uses the range of pH values established from the appropriate WQS and performs analyses, flagging pH values outside the WQS and noting upstream/downstream differences.

```{r}
pH <- function(upstreamData, downstreamData, parameter, pHspecialStandards, pHrangeAllowance){
  # Add pH_Inst fields if no pH_Inst data retrieved from probes, populate with NA 
  if(unique(c('pH_Inst',"pH_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('pH_Inst',"pH_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime')) %>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0 | upstream > 14, NA ),
           downstream = replace(downstream, downstream < 0 | downstream > 14, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream, 
           pctDiff=(numericDiff/downstream)*100)
  
  pHbyWQS(together, pHspecialStandards, pHrangeAllowance)
}
```

#### Specific Conductivity

SpCondByDesignation() is a helper function that operates inside SpCond(). The SpCondByDesignation() takes a dataset manipulated by SpCond() and applies the approprate Specific Conductivity criteria. Criteria were developed for each gage by a workgroup of Regional Biologists based on watershed size, local geology, and firsthand knowledge of the macroinvertebrate and fish communities. The criteria designate expectations for specific conductivity readings at 200 uS/cm or 500 uS/cm. Data output in the spCond_upstreamFlag/spCond_downstreamFlag columns flag any specific conductivity values above the maximum criteria for that gage. The spCond_upDownNumericDifferenceFlag flags results where the difference between the upstream/downstream gage pairs is higher than a criteria established by the specific conductivity expectations. The upstream/downstream numeric difference is compared against 50 uS/cm in lower conductivity systems (200 uS/cm) and against 100 uS/cm in higher conductivity systems (500 uS/cm). The spCond_upDownPercentDifferenceFlag column represents the results from comparing the two gages and flags any pairs of measures that are over 20% different for all gage pairs within low conductivity systems. The spCond_upDownPercentDifferenceFlag ignores upstream/downstream percent changes as these generally larger systems can maintain higher differences naturally or during storm events.

```{r}
SpCondByDesignation <- function(x,SpCond_Designation){
  upDownDifferenceThreshold <- ifelse(SpCond_Designation==500,100,50)
  
  mutate(x,spCond_upstreamFlag=ifelse(upstream > SpCond_Designation,1,0), 
         spCond_downstreamFlag=ifelse(downstream > SpCond_Designation,1,0),
         spCond_upDownNumericDifferenceFlag = ifelse(numericDiff>upDownDifferenceThreshold,1,0)) %>% # Flag if upstream/downstream numeric difference > allowed range
    rowwise()%>% # Make sure the upDownDifferenceThreshold p
    mutate(spCond_upDownPercentDifferenceFlag = ifelse(upDownDifferenceThreshold==100,
                                                            ifelse(pctDiff>20,1,0), "Not Applicable")) # Flag if upstream/downstream percent difference > allowed range, only for high conductivity sites
}
```

The SpCond() performs QA and manipulation prior to applying SpCondByDesignation() to analyze data against designated specific conductivity criteria. The function ensures specific conductivity data (SpecCond_Inst) was retrieved from each gage. If a gage has not recorded specific conductivity data within the data window, the specific conductivity fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed.

The SpCond() replaces data that is outside of the normal expected range for a specific conductivity sensor in freshwater ( < 0 uS/cm) to avoid probe malfunctions from skewing analyses. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage), the upstream/downstream numeric and percent difference is calculated. Percent difference is utilized in the SpCondByDesignation() for analysis of low conductivty streams and is used for any flagging of data from sites with this designation. Lastly, the SpCondByDesignation() uses the range of specific conductivity values established from the appropriate designations and performs analyses, flagging specific conductivity values outside the expected range and noting upstream/downstream percent differences in low conductivity sites.

```{r}
SpCond <- function(upstreamData, downstreamData, parameter, SpCond_Designation){
  # Add SpecCond_Inst fields if no SpecCond_Inst data retrieved from probes, populate with NA 
  if(unique(c('SpecCond_Inst',"SpecCond_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('SpecCond_Inst',"SpecCond_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime')) %>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0, NA ),
           downstream = replace(downstream, downstream < 0, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream,
           pctDiff=(numericDiff/downstream)*100)
  
  SpCondByDesignation(together, SpCond_Designation)
}
```


#### Turbidity
The turbidity() analyzes a raw dataset for variances on a 30 minute window of data to flag windows for further investigation. Criteria are based on the 99th percentile of turbidity data collected from each gage prior to construction beginning. The background data window varies based on gage installation date, but all gages were analyzed from late summer to fall 2017 through February 2018. All gages measured turbidity over many storm events, which bolster background data ranges. The turbidity() replaces data that is outside of the normal expected range for a turbidity sensor in freshwater (0-1500 FNU) to avoid probe malfunctions from skewing analyses. If the input dataset (after replacement) does not meet the minimum 30 minute window criteria, it is not analyzed for the maximum criteria within the 30 minute rule. The rolling window calculations are applied to the upstream and downstream gage datasets separately such that if one gage does not meet the window criteria, the other gage can still be analyzed. 

First, the function ensures turbidity data (Turb_Inst) was retrieved from each gage. If a gage has not recorded turbidity data within the data window, the turbidity fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage). Next, data outside the expected range is replaced with NA's and the upstream/downstream numeric and percent difference is calculated. The turbidity_valid30minuteWindow is the amount of time captured by lagging the data by 6 rows (i.e. calculating the amount of time the tq_mutate() will be rolling over). **Rolling windows across time series data is very  difficult** Due to computational limitations, we assume the dataset is complete, meaning data was transmitted for every 5 minute interval within the hour. This assumption is critical to efficiently run any time series analysis scripts. **If data is missing within the hour**, turbidity_valid30minuteWindow will report a number higher than 30 (30 would be expected for a valid 30 minute window). Given how the tq_mutate() is programmed, one would never expect a number less than 30. One should not disregard data with turbidity_valid30minuteWindow close to an exact 30 minute result, it still contains valuable information. turbidity_NAs record how many NA's are produced when comparing the upstream and downstream turbidity measures. A NA indicates no data was available for one of the measured periods for one or both gages. Later QA steps do not pass along notifications for windows that have too many NA's. More on those QA steps later. 

To ensure the tq_mutate() does not fail, joined upstream/downstream datasets that contain less than a 30 minute window are skipped and given NA's for the appropriate turbidity upstream/downstream comparison columns. If the dataset contains at least 30 minutes of valid data, the turbidityBaseline variable is used to determine which method is used to analyze data. **Baseline turbidity levels are calculated by taking the maximum of the median upstream turbidity and median downstream turbidity measures over the data window.** For gage pairs with background turbidity <= 40 FNU, turbidityNumericFlag() is used to calculate numeric differences between gages and sum all missing data. Flags are triggered if the downstream gage turbidity is >= 6 FNU compared to the upstream gage for at least 30 minutes within the download window. For gage pairs with background turbidity > 40 FNU, turbidityPercentFlag() is used to calculate percent differences between the gages and sum all missing data. Flags are triggered if the downstream gage turbidity is >= 15% FNU than the upstream gage for at least 30 minutes within the download window. The method used for comparison is reported in the turbidity_FlagType column as either 'Numeric' or 'Percent.'
The 30 minute window criteria rules out natural perturbations (e.g. leaves or other materials temporarily skewing turbidity measures from the probes). 

The gages are then analyzed individually for instances above their unique 99th percentile criteria. Again, these 99th percentiles are calculated from each background gage dataset from installation in 2017 to February 2018. If either gage has less than 30 minutes of valid data, the gage is not run against the 99th percentile threshold. The number of NA's within the valid 30 minute window is reported in turbidity_upstreamNAs or turbidity_downstreamNAs, respectively.


```{r}
turbidity <- function(upstreamData, downstreamData, parameter, turbidityBaseline, turbidity99th1, turbidity99th2){
  # only run function if Turbidity data came from both datasets
  if(unique(c('Turb_Inst',"Turb_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
    # If gage height data available at gage then grab that, too
    if("GH_Inst" %in% names(upstreamData)){
      if(unique(upstreamData$site_no)[!is.na(unique(upstreamData$site_no))]=="0205450393"){
        gh <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,GH_Inst)%>%
          mutate(site_noGH='02054500')%>% dplyr::select(agency_cd,site_noGH,everything(),-site_no)
      }else{
        gh <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,GH_Inst)%>%
          rename(site_noGH=!!names(.[2]))}
      
    }else{gh <- dplyr::select(upstreamData,agency_cd,dateTime)%>%
        mutate(site_noGH=NA,GH_Inst=NA)%>%dplyr::select(agency_cd,site_noGH,dateTime,GH_Inst)}
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('Turb_Inst',"Turb_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
    # If gage height data available at gage then grab that, too
    if("GH_Inst" %in% names(downstreamData)){
      gh <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,GH_Inst) %>%
        rename(site_noGH=!!names(.[2]))
    }else{
      if(unique(upstreamData$site_no)[!is.na(unique(upstreamData$site_no))]=="0205450393"){
        gh <- gh}
      if(exists('gh')){gh <- gh
      }else{
          gh <- dplyr::select(downstreamData,agency_cd,dateTime)%>%
            mutate(site_noGH=NA,GH_Inst=NA)%>%dplyr::select(agency_cd,site_noGH,dateTime,GH_Inst)}}
      
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime'))%>%
    full_join(gh,by=c('agency_cd','dateTime')) %>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0 | upstream > 1500, NA ),
           downstream = replace(downstream, downstream < 0 | downstream > 1500, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream,
           pctDiff=(numericDiff/downstream)*100,
           window= lag(dateTime,6),
           turbidity_valid30minuteWindow=dateTime-lag(dateTime,6)) # lag 6 bc lag already grabs 1 row above
  
  # Calculate Baseline Turbidity for window 
  #######Old method, but bombs if no data present: if(!all(is.na(together$upstream)) | !all(is.na(together$downstream))){
  if( all( !all(is.na(together$upstream)) , !all(is.na(together$downstream)) ) ){
    turbidityBaseline <- max(median(together$upstream,na.rm=T),median(together$downstream,na.rm=T))
    }else{turbidityBaseline <- turbidityBaseline}
    
  
  # if < 7 records the rolling functions will fail, report out NA's if not enough data to run full metrics
  if(nrow(together)<7){
    tidyverse_diff_rollstats <- mutate(together,turbidity_Flag=as.numeric(NA),turbidity_NAs=as.numeric(NA),
                                       turbidity_FlagType=as.numeric(NA),turbidity_upstreamFlag99th=as.numeric(NA),
                                       turbidity_downstreamFlag99th=as.numeric(NA))
    }else{
      if(turbidityBaseline <= 40){
        tidyverse_diff_rollstats <- together %>%
          tq_mutate(
            select     = numericDiff,
            mutate_fun = rollapply, 
            # rollapply args
            width      = 7,
            align      = "right",
            by.column  = FALSE,
            FUN        = turbidityNumericFlag,
            # FUN args
            threshold  = 5.999999999) %>% mutate(turbidity_FlagType=paste('Numeric; baseline=',turbidityBaseline))
      }else{
        tidyverse_diff_rollstats <- together %>%
          tq_mutate(
            select     = pctDiff,
            mutate_fun = rollapply, 
            # rollapply args
            width      = 7,
            align      = "right",
            by.column  = FALSE,
            FUN        = turbidityPercentFlag, 
            # FUN args
            threshold  = 14.99999999) %>% mutate(turbidity_FlagType=paste('Percent; baseline=',turbidityBaseline))
      }}
  #  Prevent tq_mutate from bombing out if entire dataset fed to it is NA's
  if(nrow(filter(together,!is.na(upstream))) < 7){
    tidyverse_diff_rollstats <- mutate(tidyverse_diff_rollstats,turbidity_upstreamFlag99th=NA,turbidity_upstreamNAs=NA)
  }else{
    # Exceed 99th percentile upstream or downstream
    tidyverse_diff_rollstats <- tidyverse_diff_rollstats %>%
      tq_mutate(
        select     = upstream,
        mutate_fun = rollapply, 
        # rollapply args
        width      = 7,
        align      = "right",
        by.column  = FALSE,
        FUN        = turbidityNumericFlag,
        # FUN args
        threshold  = turbidity99th1) %>%
      rename(turbidity_upstreamFlag99th=turbidity_Flag..1,turbidity_upstreamNAs=turbidity_NAs..1)
     #for < R version 3.6.0
     #rename(turbidity_upstreamFlag99th=turbidity_Flag.1,turbidity_upstreamNAs=turbidity_NAs.1)
  }
  #  Prevent tq_mutate from bombing out if entire dataset fed to it is NA's
  if(nrow(filter(together,!is.na(downstream))) < 7){
    tidyverse_diff_rollstats <- mutate(tidyverse_diff_rollstats,turbidity_downstreamFlag99th=NA,turbidity_downstreamNAs=NA)
  }else{
    tidyverse_diff_rollstats <- tidyverse_diff_rollstats %>%
      tq_mutate(
        select     = downstream,
        mutate_fun = rollapply, 
        # rollapply args
        width      = 7,
        align      = "right",
        by.column  = FALSE,
        FUN        = turbidityNumericFlag,
        # FUN args
        threshold  = turbidity99th2) %>%
       rename(turbidity_downstreamFlag99th=turbidity_Flag..1,turbidity_downstreamNAs=turbidity_NAs..1) 
      #for < R version 3.6.0
      #rename(turbidity_downstreamFlag99th=turbidity_Flag.1,turbidity_downstreamNAs=turbidity_NAs.1) 
  }
  return(tidyverse_diff_rollstats)
}
```

#### Data Scan

Each of the functions defined above works independently to review raw data from their respective parameter; however, incorporating these separate functions into a single function to analyze pairs of gages allows us to utilize the the real processing power of R. The dataScan() takes raw data from an upstream and downstream gage as well as user inputs for each gage's WQS class (WQclassGage1 & WQclassGage2), any pH special standards and upstream/downstream range allowances (pHspecialStandards & pHrangeAllowance), the specific conductivity designation (SpCond_Designation), nearest gage height (GH_Inst), and appropriate 99th percentiles (turbidity99th1, turbidity99th2). The output of dataScan() is a combination of all the individual parameter function outputs, merging all available data across parameters, flagging data worthy of further review for each gage.


```{r}
## Apply threshold exceedance functions across time series, multitple parameters
dataScan <- function(upstreamData, downstreamData, WQclassGage1, WQclassGage2, pHspecialStandards, pHrangeAllowance, SpCond_Designation, turbidityBaseline, turbidity99th1, turbidity99th2){
  
  ## Temperature Analysis ##
  T_Results <- temperature(upstreamData,downstreamData,'Wtemp_Inst',WQclassGage1,WQclassGage2) %>% # will have to preprogram WQS class depending on site
    select(agency_cd,dateTime,site_no.x,site_no.y,WQSapplied,T_valid1hrWindow,T_upstreamMaxFlag,T_downstreamMaxFlag,
           T_upstreamHourlyChangeFlag,T_upstreamNAs,T_downstreamHourlyChangeFlag,T_downstreamNAs,T_riseAboveNaturalFlag)
  
  ## Dissolved Oxygen Analysis ##
  DO_Results <- dissolvedOxygen(upstreamData,downstreamData,'DO_Inst',WQclassGage1,WQclassGage2) %>% # will have to preprogram WQS class depending on site
    select(agency_cd,dateTime,site_no.x,site_no.y,DO_upstreamMinFlag,DO_downstreamMinFlag,DO_upDownDifferenceFlag)
  
  ## pH Analysis ##
  pH_Results <- pH(upstreamData,downstreamData,'pH_Inst',pHspecialStandards,pHrangeAllowance) %>% # will have to preprogram WQS special standards depending on site
    select(agency_cd,dateTime,site_no.x,site_no.y,pH_upstreamFlag,pH_downstreamFlag,pH_upDownDifferenceFlag)
  
  ## Specific Conductivity Analysis ##
  spCond_Results <- SpCond(upstreamData,downstreamData,'SpecCond_Inst', SpCond_Designation) %>% 
    select(agency_cd,dateTime,site_no.x,site_no.y,spCond_upstreamFlag,spCond_downstreamFlag,spCond_upDownNumericDifferenceFlag,
           spCond_upDownPercentDifferenceFlag)
  
  ## Turbidity Analysis ##
  # Choose turbidity method based on baseline parameter value
  turbidity_Results <- turbidity(upstreamData, downstreamData, 'Turb_Inst', turbidityBaseline, turbidity99th1, turbidity99th2) %>% 
    select(agency_cd,dateTime,site_no.x,site_no.y,site_noGH,GH_Inst,turbidity_valid30minuteWindow,turbidity_NAs,turbidity_FlagType,turbidity_Flag,
           turbidity_upstreamFlag99th,turbidity_upstreamNAs,turbidity_downstreamFlag99th,turbidity_downstreamNAs)
  
  allParameters <- plyr::join_all(list(T_Results,DO_Results, pH_Results, spCond_Results, turbidity_Results),by=c('agency_cd','dateTime','site_no.x','site_no.y'))
  
  return(allParameters)
}
```




