---
title: "Monitoring System Functions"
output:
  html_document: default
  html_notebook: default
---

This notebook details functions written for analysis of continuous monitoring water quality data from paired United States Geological Survey (USGS) stream gages. The functions are detailed in this Rnotebook to allow for any user to understand the analyses. To best utilize these scripts, one should convert the .Rmd  to a .R to be sourced into a script and run either manually or automatically with a cronjob.

### Retrieve  Data
Pull water quality data from National Water Information System (NWIS) server with custom date range and automatic conversion of field names to a more understandable format.
```{r}
NWISpull <- function(gageNo,start,end){
  allUnitData <- readNWISuv(siteNumbers=gageNo,
                            parameterCd=c("00010", "00095", "00300", "00400", "63680","00065"),
                            startDate=as.Date(start,"%Y-%m-%d"),
                            endDate=as.Date(end,"%Y-%m-%d"),
                            tz='America/New_York')
  allUnitData <- renameNWISColumns(allUnitData)
}
```

### Simple Exceedance of Threshold Calculations
These functions are used within other functions to significantly reduce the amount of code required to do said analyses.

Compare data to a numeric threshold.
```{r}
numericThreshold <- function(x, threshold){
  suppressWarnings(
    if(min(x,na.rm=T)==Inf){NA
    }else{ifelse(min(x,na.rm=T)>threshold,1,0) })}
```

Compare  data to a percent threshold.
```{r}
percentThreshold <- function(x,threshold){  
  suppressWarnings(
    if(min(x,na.rm=T)==Inf){NA
    }else{ifelse(min(x,na.rm=T)>threshold,1,0)  })}
```

Count number of NA's.
```{r}
NArecords <- function(x){
  sum(is.na(x))
}
```

Temperature and turbidity require their own numeric and percent (in the case of turbidity) threshold calculations to efficiently output multiple results from rolling windows when applied to the tidyquant::tq_mutate function.

Compare maximum and minimum temperature data to numeric threshold, and output associated NA's. This function is applied to a window of data to find the maximum hourly change according to 9VAC25-260-70.
```{r}
temperatureHourlyChange <- function(x,threshold){
  Tchange <- max(x, na.rm=T)-min(x, na.rm=T)
  NAs <- NArecords(x)
  violation <- ifelse(Tchange>threshold,1,0)
  z <- c(T_maxHourlyChange=Tchange, T_hourlyChangeViolation=violation,T_NAs=NAs)
  return(z)
}
```


Compare turbidity data to numeric threshold and output associated NA's.
```{r}
turbidityNumericThreshold <- function(x,threshold){
  exceed <- numericThreshold(x,threshold)
  NAs <- NArecords(x)
  z <- c(turbidity_Exceedance=exceed,turbidity_NAs=NAs)
  return(z)
}
```

Compare turbidity data to percent threshold and output associated NA's.
```{r}
turbidityPercentThreshold <- function(x,threshold){
  exceed <- numericThreshold(x,threshold)
  NAs <- NArecords(x)
  z <- c(turbidity_Exceedance=exceed,turbidity_NAs=NAs)
  return(z)
}
```

### Parameter Specific Functions
These next functions complete the analyses for each of the parameters pulled from the NWIS  server. The functions have specific rules within them to handle missing data (NA's), data out of a normal range (probe malfunctions), and data transmission failures.

#### Temperature
temperatureByWQSclass() is a helper function that operates inside of the temperature function. Henceforth, whenever describing a named function, the name of the function will be followed by () signify it is a function, e.g. temperature(). The temperatureByWQSclass() takes a dataset manipulated within the temperature() and applies specific water  quality standard (WQS) class threshold to on an hourly window of data to identify windows that are outside of the threshold set by WQS class. The temperature() replaces data that is outside of the normal expected  range for a temperature sensor in freshwater (0-40 Celsius)  to avoid probe malfunctions from skewing analyses. If the input dataset (after replacement) does not meet the minimum 1 hour window criteria, it is not analyzed for the maximum change within 1 hour rule. The rolling window calculations are applied to the upstream and downstream gage datasets separately such that if one gage does not meet the hour window criteria, the other gage can still be analyzed. Data output in the T_upstreamHourlyChangeViolation/T_downstreamHourlyChangeViolation and T_upstreamNAs/T_downstreamNAs columns represent the results from each of the hour rolling window analyses, not for the entire dataset. This method allows users to verify if enough valid data was retrieved within an hour to interpret the result accurately. 

```{r}
# Temperature Analysis
temperatureByWQSclass <- function(x, maxHourlyTchange1, maxHourlyTchange2){
  # 9VAC25-260-70. Maximum Hourly Temperature Change, UPSTREAM
  if(nrow(filter(x,!is.na(upstream))) < 13){
    x <- mutate(x,T_maxHourlyChange=NA,T_hourlyChangeViolation=NA,T_NAs=NA)
  }else{x <- tq_mutate(x,
                       select     = upstream,
                       mutate_fun = rollapply, 
                       # rollapply args
                       width      = 13,
                       align      = "right",
                       by.column  = FALSE,
                       FUN        = temperatureHourlyChange,
                       # FUN args
                       threshold  = maxHourlyTchange1)}
  # 9VAC25-260-70. Maximum Hourly Temperature Change, DOWNSTREAM  
  if(nrow(filter(x,!is.na(downstream))) < 13){
    x <- mutate(x,T_maxHourlyChange.1=NA,T_hourlyChangeViolation.1=NA,T_NAs.1=NA)
  }else{x <- tq_mutate(x,
                       select     = downstream,
                       mutate_fun = rollapply, 
                       # rollapply args
                       width      = 13,
                       align      = "right",
                       by.column  = FALSE,
                       FUN        = temperatureHourlyChange,
                       # FUN args
                       threshold  = maxHourlyTchange2)}
  x <- rename(x, T_upstreamHourlyChangeViolation= T_hourlyChangeViolation, T_upstreamNAs= T_NAs,	
              T_downstreamHourlyChangeViolation= T_hourlyChangeViolation..1, T_downstreamNAs=T_NAs..1)	
  # for < R version 3.6.0
  #x <- rename(x, T_upstreamHourlyChangeViolation= T_hourlyChangeViolation, T_upstreamNAs= T_NAs,	
  #            T_downstreamHourlyChangeViolation= T_hourlyChangeViolation.1, T_downstreamNAs=T_NAs.1)	
return(x)
}
```

The temperature() is the function that takes raw temperature data and outputs flags based on WQS  class thresholds. First, the function ensures water temperature data (Wtemp_Inst) was retrieved from each gage. If a gage has not recorded temperature data within the data window, the temperature fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed.

Based  on the WQS class that applies to the stream segment that the gage  is located on, the function establishes thresholds to test the data against for maximum temperature, natural temperature change, and maximum hourly temperature change. Natural temperature change is the difference allowed between upstream and downstream gage pairs. All WQS class thresholds applied are from 9VAC25-260-50 and 9VAC25-260-60. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage), the upstream/downstream numeric and percent difference is calculated. Percent difference is only there for visual analysis, it is  not used for any flagging of data. The T_valid1hrWindow  is the amount of time captured by lagging the data by 12 rows (i.e. calculating the amount of time the tq_mutate() will be rolling over). **Rolling windows across time series data is very  difficult** Due to computational limitations, we assume the dataset is complete, meaning data was transmitted for every 5 minute interval within the hour. This assumption is critical to efficiently run any time series analysis scripts. **If data is missing within the hour**, T_valid1hrWindow will report a number higher than 60 (60 would be expected for a valid hour window). Given how the tq_mutate() is programmed, one would never expect a number less than 60. One should not disregard data with T_valid1hrWindow close to an exact hour, it still contains valuable information. T_upstreamNAs/T_downstreamNAs record how many NA's are within the window. Later QA steps do not pass along notifications for windows that have too many NA's. More on those QA steps later. 
```{r}
temperature <- function(upstreamData, downstreamData, parameter, WQclassGage1, WQclassGage2){
  # Add Wtemp fields if no Wtemp data retrieved from probes, populate with NA 
  if(unique(c('Wtemp_Inst',"Wtemp_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('Wtemp_Inst',"Wtemp_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  # Establish thresholds based on WQS for max Temperature Violations
  if(WQclassGage1==6){maxT1 <- 20; natTchange <- 1; maxHourlyTchange1 <- 0.5}
  if(WQclassGage2==6){maxT2 <- 20; natTchange <- 1; maxHourlyTchange2 <- 0.5}
  if(WQclassGage1==5){maxT1 <- 21; natTchange <- 3; maxHourlyTchange1 <- 2}
  if(WQclassGage2==5){maxT2 <- 21; natTchange <- 3; maxHourlyTchange2 <- 2}
  if(WQclassGage1==4){maxT1 <- 31; natTchange <- 3; maxHourlyTchange1 <- 2}
  if(WQclassGage2==4){maxT2 <- 31; natTchange <- 3; maxHourlyTchange2 <- 2}
  if(WQclassGage1==3){maxT1 <- 32; natTchange <- 3; maxHourlyTchange1 <- 2}
  if(WQclassGage2==3){maxT2 <- 32; natTchange <- 3; maxHourlyTchange2 <- 2}
  # natTchange called same parameter name bc want the larger # to override smaller 
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime'))%>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0 | upstream > 40, NA ),
              downstream = replace(downstream, downstream < 0 | downstream > 40, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream,
           pctDiff=(numericDiff/downstream)*100,
           window= lag(dateTime,12),
           T_valid1hrWindow=as.double(dateTime-lag(dateTime,12),units='mins'), # lag 12 bc lag already grabs 1 row above
           T_upstreamMaxViolation=ifelse(upstream>maxT1,1,0),# 9VAC25-260-50. Numerical Criteria for Maximum Temperature
           T_downstreamMaxViolation=ifelse(downstream>maxT2,1,0), # 9VAC25-260-50. Numerical Criteria for Maximum Temperature
           T_riseAboveNaturalViolation=ifelse(numericDiff>natTchange,1,0)) # 9VAC25-260-60. Rise Above Natural Temperature
    
  temperatureByWQSclass(together, maxHourlyTchange1, maxHourlyTchange2)%>%
    mutate(WQSapplied=ifelse(WQclassGage1==WQclassGage2,WQclassGage1,paste(WQclassGage1,";",WQclassGage2,sep="")))
}
```


#### Dissolved Oxygen
dissolvedOxygenByWQSclass() is a helper function that operates inside dissolvedOxygen(). The function takes minimum dissolved oxygen values, established within dissolvedOxygen() using the WQS class for each gage and adhering to 9VAC25-260-50, and flags data that is below the threshold in DO_upstreamMinViolation/DO_downstreamMinViolation. Additionally, DO_upDownDifferenceViolation flags any sites where there is greater than 1 mg/L difference between the gages.

```{r}
dissolvedOxygenByWQSclass <- function(x,minDO1,minDO2){
  together <- mutate(x,DO_upstreamMinViolation=ifelse(upstream<minDO1,1,0), # 9VAC25-260-50. Numerical Criteria for Dissolved Oxygen
                     DO_downstreamMinViolation=ifelse(downstream<minDO2,1,0),  # 9VAC25-260-50. Numerical Criteria for Dissolved Oxygen
                     DO_upDownDifferenceViolation = ifelse(abs(numericDiff)>1,1,0)) # Flag if upstream/downstream difference > 1 mg/L
  return(together)
}

```

The dissolvedOxygen() analyzes raw data against the appropriate WQS class minimum dissolved oxygen thresholds for each gage. The function ensures dissolved oxygen data (DO_Inst) was retrieved from each gage. If a gage has not recorded dissolved oxygen data within the data window, the dissolved oxygen fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed.

Based  on the WQS class that applies to the stream segment that the gage  is located on, the function establishes thresholds to test the data against for minimum dissolved oxygen and maximum change between upstream and downstream gage pairs. The dissolvedOxygen() replaces data that is outside of the normal expected range for a dissolved oxygen sensor in freshwater (0-25 mg/L) to avoid probe malfunctions from skewing analyses. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage), the upstream/downstream numeric and percent difference is calculated. Percent difference is only there for visual analysis, it is  not used for any flagging of data. Lastly, the dissolvedOxygenByWQSclass() uses the minimum dissolved oxygen values established from teh appropriate WQS class and performs analyses, flagging dissolved oxygen values below the WQS and noting upstream/downstream differences.

```{r}
dissolvedOxygen <- function(upstreamData, downstreamData, parameter, WQclassGage1, WQclassGage2){
  # Add DO_Inst fields if no DO_Inst data retrieved from probes, populate with NA 
  if(unique(c('DO_Inst',"DO_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('DO_Inst',"DO_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  # Establish thresholds based on WQS for min DO violations
  if(WQclassGage1==6){minDO1 <- 8}
  if(WQclassGage2==6){minDO2 <- 8}
  if(WQclassGage1 %in% c(3,4,5)){minDO1 <- 7}
  if(WQclassGage2 %in% c(3,4,5)){minDO2 <- 7}
  
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime')) %>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0 | upstream > 25, NA ),
           downstream = replace(downstream, downstream < 0 | downstream > 25, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream,
           pctDiff=(numericDiff/downstream)*100)
  
  dissolvedOxygenByWQSclass(together,minDO1,minDO2)%>%
    mutate(WQSapplied=ifelse(WQclassGage1==WQclassGage2,WQclassGage1,paste(WQclassGage1,";",WQclassGage2,sep="")))
}
```

#### pH
pHbyWQS() is a helper function that operates inside pH(). The pHbyWQS() takes a dataset manipulated within pH() and applies the approprate WQS according to 9VAC25-260-50 and any special WQS thresholds, where applicable. Data output in the pH_upstreamViolation/pH_downstreamViolation columns flag any pH values outside of the WQS  for that gage. The pH_upDownDifferenceViolation columns represents the results from comparing the two gages and flags any pairs of measures that fall outside of the pH range allowed for the gage pairs. The Cowpasture is the only gage pair at present that has a pH range allowance about 0,5 standard units due to known natural spring inputs that alter pH between the gages.

```{r}
pHbyWQS <- function(x,pHspecialStandards,pHrangeAllowance){
  # Adjust standards if WQS special standard for site
  min_pH <- ifelse(pHspecialStandards=="Y",6.5,6)
  max_pH <- ifelse(pHspecialStandards=="Y",9.5,9)
  
  together <- mutate(x,pH_upstreamViolation=ifelse(upstream > min_pH & upstream < max_pH,0,1), # 9VAC25-260-50. Numerical Criteria for pH
                     pH_downstreamViolation=ifelse(downstream > min_pH & downstream < max_pH,0,1),  # 9VAC25-260-50. Numerical Criteria for pH
                     pH_upDownDifferenceViolation = ifelse(abs(numericDiff)>pHrangeAllowance,1,0)) # Flag if upstream/downstream difference > allowed range
  return(together)
}
```

The pH() performs QA and manipulation prior to applying pHbyWQS() for analyzes of data against the appropriate WQS. The function ensures pH data (pH_Inst) was retrieved from each gage. If a gage has not recorded pH data within the data window, the pH fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed.

The pH() replaces data that is outside of the normal expected range for a pH sensor in freshwater (0-14 standard units) to avoid probe malfunctions from skewing analyses. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage), the upstream/downstream numeric and percent difference is calculated. Percent difference is only there for visual analysis, it is  not used for any flagging of data. Lastly, the pHbyWQS() uses the range of pH values established from the appropriate WQS and performs analyses, flagging pH values outside the WQS and noting upstream/downstream differences.

```{r}
pH <- function(upstreamData, downstreamData, parameter, pHspecialStandards, pHrangeAllowance){
  # Add pH_Inst fields if no pH_Inst data retrieved from probes, populate with NA 
  if(unique(c('pH_Inst',"pH_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('pH_Inst',"pH_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime')) %>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0 | upstream > 14, NA ),
           downstream = replace(downstream, downstream < 0 | downstream > 14, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream, 
           pctDiff=(numericDiff/downstream)*100)
  
  pHbyWQS(together, pHspecialStandards, pHrangeAllowance)
}
```

#### Specific Conductivity

SpCondByDesignation() is a helper function that operates inside SpCond(). The SpCondByDesignation() takes a dataset manipulated by SpCond() and applies the approprate Specific Conductivity threshold. Thesholds were developed for each gage by a workgroup of Regional Biologists based on watershed size, local geology, and firsthand knowledge of the macroinvertebrate and fish communities. The thresholds designate expectations for specific conductivity readings below 100 uS/cm or 500 uS/cm. Data output in the spCond_upstreamViolation/spCond_downstreamViolation columns flag any specific conductivity values above the maximum threshold for that gage. The spCond_upDownNumericDifferenceViolation column represents the results from comparing the two gages and flags any pairs of measures that are over 20% different for all gage pairs within low conductivity systems. The spCond_upDownNumericDifferenceViolation ignores upstream/downstream percent changes as these generally larger systems can maintain higher differences naturally or during storm events.

```{r}
SpCondByDesignation <- function(x,SpCond_Designation){
  upDownDifferenceThreshold <- ifelse(SpCond_Designation==500,100,50)
  
  mutate(x,spCond_upstreamViolation=ifelse(upstream > SpCond_Designation,1,0), 
         spCond_downstreamViolation=ifelse(downstream > SpCond_Designation,1,0),
         spCond_upDownNumericDifferenceViolation = ifelse(numericDiff>upDownDifferenceThreshold,1,0)) %>% # Flag if upstream/downstream numeric difference > allowed range
    rowwise()%>% # Make sure the upDownDifferenceThreshold p
    mutate(spCond_upDownPercentDifferenceViolation = ifelse(upDownDifferenceThreshold==100,
                                                            ifelse(pctDiff>20,1,0), "Not Applicable")) # Flag if upstream/downstream percent difference > allowed range, only for high conductivity sites
}
```

The SpCond() performs QA and manipulation prior to applying SpCondByDesignation() for analyzes of data against the appropriate specific conductivity threshold. The function ensures specific conductivity data (SpecCond_Inst) was retrieved from each gage. If a gage has not recorded specific conductivity data within the data window, the specific conductivity fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed.

The SpCond() replaces data that is outside of the normal expected range for a specific conductivity sensor in freshwater (0-? uS/cm) to avoid probe malfunctions from skewing analyses. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage), the upstream/downstream numeric and percent difference is calculated. Percent difference is utilized in the SpCondByDesignation() for analysis of low conductivty streams and is used for any flagging of data from sites with this designation. Lastly, the SpCondByDesignation() uses the range of specific conductivity values established from the appropriate designations and performs analyses, flagging specific conductivity values outside the expected range and noting upstream/downstream percent differences in low conductivity sites.

```{r}
SpCond <- function(upstreamData, downstreamData, parameter, SpCond_Designation){
  # Add SpecCond_Inst fields if no SpecCond_Inst data retrieved from probes, populate with NA 
  if(unique(c('SpecCond_Inst',"SpecCond_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('SpecCond_Inst',"SpecCond_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime')) %>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0, NA ),
           downstream = replace(downstream, downstream < 0, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream,
           pctDiff=(numericDiff/downstream)*100)
  
  SpCondByDesignation(together, SpCond_Designation)
}
```


#### Turbidity
The turbidity() analyzes a raw dataset for exceedances of a threshold on a 30 minute window of data to flag windows that are above of the threshold. Thresholds are based on the 99th percentile of turbidity data collected from each gage prior to construction beginning. The background data window varies based on gage installation date, but all gages were analyzed from late summer to fall 2017 to February 2018. All gages measured turbidity over many storm events, which bolster background data ranges. The turbidity() replaces data that is outside of the normal expected range for a turbidity sensor in freshwater (0-1500 FNU) to avoid probe malfunctions from skewing analyses. If the input dataset (after replacement) does not meet the minimum 30 minute window criteria, it is not analyzed for the maximum threshold within 30 minute rule. The rolling window calculations are applied to the upstream and downstream gage datasets separately such that if one gage does not meet the window criteria, the other gage can still be analyzed. 

First, the function ensures turbidity data (Turb_Inst) was retrieved from each gage. If a gage has not recorded turbidity data within the data window, the turbidity fields will not be present and can stop the function from running properly. Thus, if the fields are not there, the function creates said fields and populates them with NA's for the data window being analyzed. 

The upstream and downstream data are joined together (using dplyr::full_join as to not lose any records if one of the gages does not have a record for a time that matches the other gage). Next, data outside the expected range is replaced with NA's and the upstream/downstream numeric and percent difference is calculated. The turbidity_valid30minuteWindow is the amount of time captured by lagging the data by 6 rows (i.e. calculating the amount of time the tq_mutate() will be rolling over). **Rolling windows across time series data is very  difficult** Due to computational limitations, we assume the dataset is complete, meaning data was transmitted for every 5 minute interval within the hour. This assumption is critical to efficiently run any time series analysis scripts. **If data is missing within the hour**, turbidity_valid30minuteWindow will report a number higher than 30 (30 would be expected for a valid 30 minute window). Given how the tq_mutate() is programmed, one would never expect a number less than 30. One should not disregard data with turbidity_valid30minuteWindow close to an exact 30 minute result, it still contains valuable information. turbidity_NAs record how many NA's are produced when comparing the upstream and downstream turbidity measures. A NA indicates no data was available for one of the measured periods for one or both gages. Later QA steps do not pass along notifications for windows that have too many NA's. More on those QA steps later. 

To ensure the tq_mutate() does not fail, joined upstream/downstream datasets that contain less than a 30 minute window are skipped and given NA's for the appropriate turbidity upstream/downstream comparison columns. If the dataset contains at least 30 minutes of valid data, the turbidityBaseline variable is used to determine which method is used to analyze data. Baseline turbidity thesholds are calculated by taking the maximum of the median upstream turbidity and median downstream turbidity measures over the two hour data window. For gage pairs with background turbidity <= 40  FNU threshold, turbidityNumericThreshold() is used to calculate numeric differences between gages and sum all missing data. Flags are triggered if the downstream gage turbidity is >= 6 FNU than the upstream gage for at least 30 minutes within the download window. For gage pairs with background turbidity > 40 FNU, turbidityPercentThreshold() is used to calculate percent differences between the gages and sum all missing data. Flags are triggered if the downstream gage turbidity is >= 15% FNU than the upstream gage for at least 30 minutes within the download window. The method used for comparison is reported in the turbidity_ExceedanceType column as either 'Numeric' or 'Percent.'
The 30 minute window criteria rules out natural perturbations (e.g. leaves or other materials temporarily skewing turbidity measures from the probes). 

The gages are then analyzed individually for instances above their unique 99th percentile threshold. Again, these 99 percentiles are calculated from each background gage dataset from installation in 2017 to February 2018. If either gage has less than 30 minutes of valid data, the gage is not run against the 99th percentile threshold. The number of NA's within the valid 30 minute window is reported in turbidity_upstreamNAs or turbidity_downstreamNAs, respectively.


```{r}
turbidity <- function(upstreamData, downstreamData, parameter, turbidityBaseline, turbidity99th1, turbidity99th2){
  # only run function if Turbidity data came from both datasets
  if(unique(c('Turb_Inst',"Turb_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
    # If gage height data available at gage then grab that, too
    if("GH_Inst" %in% names(upstreamData)){
      if(unique(upstreamData$site_no)[!is.na(unique(upstreamData$site_no))]=="0205450393"){
        gh <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,GH_Inst)%>%
          mutate(site_noGH='02054500')%>% dplyr::select(agency_cd,site_noGH,everything(),-site_no)
      }else{
        gh <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,GH_Inst)%>%
          rename(site_noGH=!!names(.[2]))}
      
    }else{gh <- dplyr::select(upstreamData,agency_cd,dateTime)%>%
        mutate(site_noGH=NA,GH_Inst=NA)%>%dplyr::select(agency_cd,site_noGH,dateTime,GH_Inst)}
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('Turb_Inst',"Turb_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,parameter)%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
    # If gage height data available at gage then grab that, too
    if("GH_Inst" %in% names(downstreamData)){
      gh <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,GH_Inst) %>%
        rename(site_noGH=!!names(.[2]))
    }else{
      if(unique(upstreamData$site_no)[!is.na(unique(upstreamData$site_no))]=="0205450393"){
        gh <- gh}
      if(exists('gh')){gh <- gh
      }else{
          gh <- dplyr::select(downstreamData,agency_cd,dateTime)%>%
            mutate(site_noGH=NA,GH_Inst=NA)%>%dplyr::select(agency_cd,site_noGH,dateTime,GH_Inst)}}
      
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime'))%>%
    full_join(gh,by=c('agency_cd','dateTime')) %>%
    # Ensure data is realistic, replace wonky probe readings with NA so they are skipped
    # Filtering out bad data is not a good idea because you will lose entire rows of data and subsequently
    #  throw off other analyses down the line
    mutate(upstream = replace(upstream, upstream < 0 | upstream > 1500, NA ),
           downstream = replace(downstream, downstream < 0 | downstream > 1500, NA )) %>%
    mutate(parameter=parameter,
           numericDiff=downstream-upstream,
           pctDiff=(numericDiff/downstream)*100,
           window= lag(dateTime,6),
           turbidity_valid30minuteWindow=dateTime-lag(dateTime,6)) # lag 6 bc lag already grabs 1 row above
  
  # Calculate Baseline Turbidity for 2hr window 
  if(!all(is.na(together$upstream)) | !all(is.na(together$downstream))){
    turbidityBaseline <- max(median(together$upstream,na.rm=T),median(together$downstream,na.rm=T))
    }else{turbidityBaseline <- turbidityBaseline}
    
  
  # if < 7 records the rolling functions will fail, report out NA's if not enough data to run full metrics
  if(nrow(together)<7){
    tidyverse_diff_rollstats <- mutate(together,turbidity_Exceedance=as.numeric(NA),turbidity_NAs=as.numeric(NA),
                                       turbidity_ExceedanceType=as.numeric(NA),turbidity_upstreamExceed99th=as.numeric(NA),
                                       turbidity_downstreamExceed99th=as.numeric(NA))
    }else{
      if(turbidityBaseline <= 40){
        tidyverse_diff_rollstats <- together %>%
          tq_mutate(
            select     = numericDiff,
            mutate_fun = rollapply, 
            # rollapply args
            width      = 7,
            align      = "right",
            by.column  = FALSE,
            FUN        = turbidityNumericThreshold,
            # FUN args
            threshold  = 5.999999999) %>% mutate(turbidity_ExceedanceType=paste('Numeric; baseline=',turbidityBaseline))
      }else{
        tidyverse_diff_rollstats <- together %>%
          tq_mutate(
            select     = pctDiff,
            mutate_fun = rollapply, 
            # rollapply args
            width      = 7,
            align      = "right",
            by.column  = FALSE,
            FUN        = turbidityPercentThreshold, 
            # FUN args
            threshold  = 14.99999999) %>% mutate(turbidity_ExceedanceType=paste('Percent; baseline=',turbidityBaseline))
      }}
  #  Prevent tq_mutate from bombing out if entire dataset fed to it is NA's
  if(nrow(filter(together,!is.na(upstream))) < 7){
    tidyverse_diff_rollstats <- mutate(tidyverse_diff_rollstats,turbidity_upstreamExceed99th=NA,turbidity_upstreamNAs=NA)
  }else{
    # Exceed 99th percentile upstream or downstream
    tidyverse_diff_rollstats <- tidyverse_diff_rollstats %>%
      tq_mutate(
        select     = upstream,
        mutate_fun = rollapply, 
        # rollapply args
        width      = 7,
        align      = "right",
        by.column  = FALSE,
        FUN        = turbidityNumericThreshold,
        # FUN args
        threshold  = turbidity99th1) %>%
      rename(turbidity_upstreamExceed99th=turbidity_Exceedance..1,turbidity_upstreamNAs=turbidity_NAs..1)
     #for < R version 3.6.0
     #rename(turbidity_upstreamExceed99th=turbidity_Exceedance.1,turbidity_upstreamNAs=turbidity_NAs.1)
  }
  #  Prevent tq_mutate from bombing out if entire dataset fed to it is NA's
  if(nrow(filter(together,!is.na(downstream))) < 7){
    tidyverse_diff_rollstats <- mutate(tidyverse_diff_rollstats,turbidity_downstreamExceed99th=NA,turbidity_downstreamNAs=NA)
  }else{
    tidyverse_diff_rollstats <- tidyverse_diff_rollstats %>%
      tq_mutate(
        select     = downstream,
        mutate_fun = rollapply, 
        # rollapply args
        width      = 7,
        align      = "right",
        by.column  = FALSE,
        FUN        = turbidityNumericThreshold,
        # FUN args
        threshold  = turbidity99th2) %>%
       rename(turbidity_downstreamExceed99th=turbidity_Exceedance..1,turbidity_downstreamNAs=turbidity_NAs..1) 
      #for < R version 3.6.0
      #rename(turbidity_downstreamExceed99th=turbidity_Exceedance.1,turbidity_downstreamNAs=turbidity_NAs.1) 
  }
  return(tidyverse_diff_rollstats)
}
```

#### Data Scan

Each of the functions defined above works independently to review raw data from their respective parameter; however, incorporating these separate functions into a single function to analyze pairs of gages allows us to utilize the the real processing power of R. The dataScan() takes raw data from an upstream and downstream gage as well as user inputs for each gage's WQS class (WQclassGage1 & WQclassGage2), any pH special standards and upstream/downstream range allowances (pHspecialStandards & pHrangeAllowance), the specific conductivity designation (SpCond_Designation), nearest gage height (GH_Inst), and baseline turbidity (turbidityBaseline) and appropriate 99th percentiles (turbidity99th1, turbidity99th2). The output of dataScan() is a combination of all the individual parameter function outputs, merging all available data across parameters, with flags associated data that are outside of the defined threshold for that gage.


```{r}
## Apply threshold exceedance functions across time series, multitple parameters
dataScan <- function(upstreamData, downstreamData, WQclassGage1, WQclassGage2, pHspecialStandards, pHrangeAllowance, SpCond_Designation, turbidityBaseline, turbidity99th1, turbidity99th2){
  
  ## Temperature Analysis ##
  T_Results <- temperature(upstreamData,downstreamData,'Wtemp_Inst',WQclassGage1,WQclassGage2) %>% # will have to preprogram WQS class depending on site
    select(agency_cd,dateTime,site_no.x,site_no.y,WQSapplied,T_valid1hrWindow,T_upstreamMaxViolation,T_downstreamMaxViolation,
           T_upstreamHourlyChangeViolation,T_upstreamNAs,T_downstreamHourlyChangeViolation,T_downstreamNAs,T_riseAboveNaturalViolation)
  
  ## Dissolved Oxygen Analysis ##
  DO_Results <- dissolvedOxygen(upstreamData,downstreamData,'DO_Inst',WQclassGage1,WQclassGage2) %>% # will have to preprogram WQS class depending on site
    select(agency_cd,dateTime,site_no.x,site_no.y,DO_upstreamMinViolation,DO_downstreamMinViolation,DO_upDownDifferenceViolation)
  
  ## pH Analysis ##
  pH_Results <- pH(upstreamData,downstreamData,'pH_Inst',pHspecialStandards,pHrangeAllowance) %>% # will have to preprogram WQS special standards depending on site
    select(agency_cd,dateTime,site_no.x,site_no.y,pH_upstreamViolation,pH_downstreamViolation,pH_upDownDifferenceViolation)
  
  ## Specific Conductivity Analysis ##
  spCond_Results <- SpCond(upstreamData,downstreamData,'SpecCond_Inst', SpCond_Designation) %>% 
    select(agency_cd,dateTime,site_no.x,site_no.y,spCond_upstreamViolation,spCond_downstreamViolation,spCond_upDownNumericDifferenceViolation,
           spCond_upDownPercentDifferenceViolation)
  
  ## Turbidity Analysis ##
  # Choose turbidity method based on baseline parameter value
  turbidity_Results <- turbidity(upstreamData, downstreamData, 'Turb_Inst', turbidityBaseline, turbidity99th1, turbidity99th2) %>% 
    select(agency_cd,dateTime,site_no.x,site_no.y,site_noGH,GH_Inst,turbidity_valid30minuteWindow,turbidity_NAs,turbidity_ExceedanceType,turbidity_Exceedance,
           turbidity_upstreamExceed99th,turbidity_upstreamNAs,turbidity_downstreamExceed99th,turbidity_downstreamNAs)
  
  allParameters <- plyr::join_all(list(T_Results,DO_Results, pH_Results, spCond_Results, turbidity_Results),by=c('agency_cd','dateTime','site_no.x','site_no.y'))
  
  return(allParameters)
}
```







###Notification Functions

After analyzing the raw NWIS data for each upstream/downstream gage pair, it is necessary to send information of exceedances to scientists for further review. Twitter is an efficient and secure way to send information from the R console to a specific list of users. The secure connection from R to Twitter is established through [OAuth2.0](https://oauth.net/2/), which creates a unique 'handshake' between R and Twitter each time data is passed between the two applications. The Twitter app associated with the R environment uses a random character strings to establish a consumer key, consumer secret key, access token, and access secret token to link the applications. These four random strings are private to the R developer and prevent an other user from being able to tweet to the linked Twitter handle.

Tweeting messages from R to a protected Twitter handle ensures only users approved by the Twitter handle administrator (the R script developer) have access to the information reported to the Twitter feed. The Twitter feed also acts as an archive for any approved user to see what has triggered notifications in the past. The unique identifier (UID) noted in each tweet matches to the name of the flat file saved from R with the data responsible for triggering the tweet. Additionally, a Twitter feed does not limit the number of notifications send from R within a time period, unlike most email or SMS text notification options. Twitter is the only secure option currently available to match the speed with which R analyzes and outputs notifications. Other SMTP email/text options are limited by the number or volume of notifications available within a time period (typically 24 hours).


The following functions are used within other functions to significantly reduce the amount of code required to convert the output of gageResults() to tweets that are understandable by any authorized user.

Based on column name, output upstream or downstream gage number.
```{r}
updownDifference <-function(colName,gageResults){
  if(length(grep('upstream',colName))){
    return(unique(gageResults$site_no.x)[!is.na(unique(gageResults$site_no.x))])}
  if(length(grep('downstream',colName))){
    return(unique(gageResults$site_no.y)[!is.na(unique(gageResults$site_no.y))])}}  
```

Based on column name, output parameter code (for weblink).
```{r}
parameterCodeDecipher <- function(colName){
  if(length(grep('T',colName,ignore.case = F))){return('00010')}
  if(length(grep('DO',colName,ignore.case = F))){return('00300')}
  if(length(grep('pH',colName,ignore.case = F))){return('00400')}
  if(length(grep('spCond',colName,ignore.case = F))){return('00095')}
  if(length(grep('turbidity',colName,ignore.case = F))){return('63680')}}
```

Based on gage number, output stream name.
```{r}
gageNumberToStream <- function(gageNumber){
  gageInfo[grep(as.numeric(gageNumber),gageInfo$`USGS Station ID`),]$`Stream Name`[1]}
```


### Functions for Tweeting
The functions below utilize the functions defined above to convert information output from the gageResults() to tweets with an appropriate stream name, parameter notification, and UID as well as web link to the NWIS server with the associated gage, parameter, and data window of interest automatically established.

#### Send tweet for any metrics that require 5 min exceedance for notification.
The anyExceedance() subsets the gageResults() output for metrics that are allowed to send notifications with as little as a single 5  minute flag. These metrics are maxima and minima exceedances for temperature, dissolved oxygen, pH, and specific conductivity that require further data review before warranting any action. The function first establishes the appropriate stream name, parameter notification, and UID and necessary inputs to the NWIS server to link to a page that graphs the appropriate gage(s), parameter(s), and data window. The anyExceedance() only sends a tweet if at least one flag is present for a metric  in the gageResults() output. Additionally, the function saves a copy of the gageResults() and raw data responisble for sending the notification in a flat file. The UID from the tweet can be matched to the flat file name if any review  of raw data or analysis is required at a later point in time.

```{r}
anyExceedance <- function(gageResults,upstreamData,downstreamData){
  minmaxData <- select(gageResults,dateTime,site_no.x,site_no.y,T_upstreamMaxViolation,
                       T_downstreamMaxViolation,T_riseAboveNaturalViolation,DO_upstreamMinViolation,
                       DO_downstreamMinViolation,DO_upDownDifferenceViolation,
                       pH_upstreamViolation,pH_downstreamViolation,pH_upDownDifferenceViolation,
                       spCond_upstreamViolation,spCond_downstreamViolation,
                       spCond_upDownNumericDifferenceViolation,spCond_upDownPercentDifferenceViolation)
  
  for(i in 4:length(minmaxData)){# start at 4 bc first columns are gage numbers and date
    if(!all(is.na(minmaxData[,i]))){# skip column if all values are NA
      columnName <- colnames(minmaxData)[i]
      PCcolName <- gsub("Violation","DataReview",columnName) # PC name for tweet
      date1 <- as.Date(minmaxData$dateTime[1])-3 # Need to hardwire date into link so get same results well after original notification
      date2 <- as.Date(minmaxData$dateTime[1]) # Need to hardwire date into link so get same results well after original notification
      parameterCode <- parameterCodeDecipher(columnName) # change parameter from column name to USGS parameter code for link
      uniqueTweetIdentifier <- format(as.numeric(Sys.time()),nsmall=4) # Tweet function will not work if the status is the same as a previous status
      if(length(grep('T',columnName,ignore.case = F))){selection <- c("Wtemp_Inst","Wtemp_Inst_cd")}
      if(length(grep('DO',columnName,ignore.case = F))){selection <- c("DO_Inst","DO_Inst_cd")}
      if(length(grep('pH',columnName,ignore.case = F))){selection <- c("pH_Inst","pH_Inst_cd")}
      if(length(grep('spCond',columnName,ignore.case = F))){selection <- c("SpecCond_Inst","SpecCond_Inst_cd")}
      if(length(grep('turbidity',columnName,ignore.case = F))){selection <- c("Turb_Inst","Turb_Inst_cd")}
      
      
      if(length(grep("riseAboveNatural",columnName)) > 0 | length(grep('upDown',columnName)) > 0){
        gageNumber1 <- unique(minmaxData$site_no.x)[!is.na(unique(minmaxData$site_no.x))]
        gageNumber2 <- unique(minmaxData$site_no.y)[!is.na(unique(minmaxData$site_no.y))]
        streamName <- gageInfo[grep(as.numeric(gageNumber1),gageInfo$`USGS Station ID`),]$`Stream Name`[1]
        weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                         '&cb_',parameterCode,'=on&site_no=',gageNumber1,'%2C',gageNumber2,'&format=gif_mult_sites',sep='')
        datToSave <- minmaxData[,c(1:3,i)]
        upstreamRAW <- select(upstreamData,site_no,dateTime,selection)
        names(upstreamRAW)[c(1,3:4)] <- paste(names(upstreamRAW)[c(1,3:4)],".x",sep="")
        downstreamRAW <- select(downstreamData,site_no,dateTime,selection)
        names(downstreamRAW)[c(1,3:4)] <- paste(names(downstreamRAW)[c(1,3:4)],".y",sep="")
        datToSave <- plyr::join_all(list(datToSave,upstreamRAW,downstreamRAW),by='dateTime')
      }else{
        gageNumber <- updownDifference(columnName,minmaxData)
        streamName <- gageInfo[grep(as.numeric(gageNumber),gageInfo$`USGS Station ID`),]$`Stream Name`[1]
        weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                         '&cb_',parameterCode,'=on&site_no=',gageNumber,sep = "")
        #Pull together data to save for archive
        if(length(grep('upstream',columnName)) > 0){
          otherRAWdata  <- select(upstreamData,dateTime,site_no,selection)
          datToSave <- minmaxData[,c(1:2,i)] %>%
            full_join(otherRAWdata,by='dateTime')}
        if(length(grep('downstream',columnName)) > 0){
          otherRAWdata  <- select(downstreamData,dateTime,site_no,selection)
          datToSave <- minmaxData[,c(1,3,i)] %>%
            full_join(otherRAWdata,by='dateTime')}
      }
      if(1 %in% minmaxData[,i]){ # If there is a single 5 min violation for a metric, send tweet and save analysis
        tweet(paste(streamName,PCcolName,weblink,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T)
        write.csv(datToSave,paste('notifications/',uniqueTweetIdentifier,'.csv',sep=""),row.names = F)}
    }}
}
```


#### Tweet if any temperature hourly change noted (based on stream WQS)
The tempTimeTweet() subsets the gageResults() output for temperature hourly change metrics. For these metric to flag, there must be a hourly stream temperature change noted above the WQS for the segment on which the gage is located. The hour window is verified and any hour windows noting 4 or more NA's (more than one third of the data missing) are discounted prior to sending a tweet. After removing invalid windows of data, any flags of temperature change above the appropriate threshold sustained for one hour (or longer) will send a tweet. These notifications are triggered by valid upstream or downstream flags.

If a notification is necessary, the function establishes the appropriate stream name, parameter notification, and UID and necessary inputs to the NWIS server to link to a page that graphs the appropriate gage(s), parameter, and data window. Additionally, the function saves a copy of the gageResults() and raw data responisble for sending the notification in a flat file. The UID from the tweet can be matched to the flat file name if any review  of raw data or analysis is required at a later point in time. 

```{r}
tempTimeTweet <- function(gageResults,upstreamData,downstreamData){
  tempTimeData <- select(gageResults,dateTime,site_no.x,site_no.y,WQSapplied,T_valid1hrWindow,
                         T_upstreamHourlyChangeViolation,T_upstreamNAs,
                         T_downstreamHourlyChangeViolation,T_downstreamNAs)
  
  # Only use data from correct 1hr window
  validData <- filter(tempTimeData,T_valid1hrWindow==60)
  if(nrow(validData)>0){
    # Upstream Analysis
    validUP <- filter(validData,T_upstreamHourlyChangeViolation>0, # Limit dataset to only violations
                      T_upstreamNAs <=4) # Only allow up to 4 missing Temperature reading per hour for any hour to count toward max change rate violation
    # Only send tweet if at least 1 valid row (1 hr violation) & <= 4 missing Temperature readings within hour
    if(nrow(validUP)>0){
      uniqueTweetIdentifier <- format(as.numeric(Sys.time()),nsmall=4) # Tweet function will not work if the status is the same as a previous status
      PCcolName <- 'T_upstreamHourlyChangeDataReview'
      gageNumber <- unique(validData$site_no.x)[!is.na(unique(validData$site_no.x))]
      streamName <- gageInfo[grep(as.numeric(gageNumber),gageInfo$`USGS Station ID`),]$`Stream Name`[1]
      date1 <- as.Date(validData$dateTime[1])-3 # Need to hardwire date into link so get same results well after original notification
      date2 <- as.Date(validData$dateTime[1]) # Need to hardwire date into link so get same results well after original notification
      weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                       '&cb_00010=on&site_no=',gageNumber,sep = "")
      tweet(paste(streamName,PCcolName,weblink,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T)
      # Save a record of the data that caused the tweet, indexed by uniqueTweetIdentifier
      datToSave <- tempTimeData[,c(1,2,4:7)]
      upstreamRAW <- select(upstreamData,site_no,dateTime,Wtemp_Inst,Wtemp_Inst_cd) %>%
        dplyr::rename(site_no.x=site_no,Wtemp_Inst.x=Wtemp_Inst,Wtemp_Inst_cd.x=Wtemp_Inst_cd)
      datToSave <- plyr::join_all(list(datToSave,upstreamRAW),by='dateTime')
      write.csv(datToSave,paste('notifications/',uniqueTweetIdentifier,'.csv',sep=""),row.names = F)
    }
    # Downstream Analysis
    validDOWN <- filter(validData,T_downstreamHourlyChangeViolation>0, # Limit dataset to only violations
                        T_downstreamNAs <=4) # Only allow up to 4 missing Temperature reading per hour for any hour to count toward max change rate violation
    # Only send tweet if at least 1 valid row (1 hr violation) & <= 4 missing Temperature readings within hour
    if(nrow(validDOWN)>0){
      uniqueTweetIdentifier <- format(as.numeric(Sys.time()),nsmall=4) # Tweet function will not work if the status is the same as a previous status
      PCcolName <- 'T_downstreamHourlyChangeDataReview'
      gageNumber <- unique(validData$site_no.y)[!is.na(unique(validData$site_no.y))]
      streamName <- gageInfo[grep(as.numeric(gageNumber),gageInfo$`USGS Station ID`),]$`Stream Name`[1]
      date1 <- as.Date(validData$dateTime[1])-3 # Need to hardwire date into link so get same results well after original notification
      date2 <- as.Date(validData$dateTime[1]) # Need to hardwire date into link so get same results well after original notification
      weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                       '&cb_00010=on&site_no=',gageNumber,sep = "")
      tweet(paste(streamName,PCcolName,weblink,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T)
      # Save a record of the data that caused the tweet, indexed by uniqueTweetIdentifier
      datToSave <- tempTimeData[,c(1,3:5,8,9)]
      downstreamRAW <- select(downstreamData,site_no,dateTime,Wtemp_Inst,Wtemp_Inst_cd) %>%
        dplyr::rename(site_no.y=site_no,Wtemp_Inst.y=Wtemp_Inst,Wtemp_Inst_cd.y=Wtemp_Inst_cd)
      datToSave <- plyr::join_all(list(datToSave,downstreamRAW),by='dateTime')
      write.csv(datToSave,paste('notifications/',uniqueTweetIdentifier,'.csv',sep=""),row.names = F)}
  }
}
```

#### Tweet if any turbidity 30 minute change noted (based on median baseline turbidity and 99th percentile thresholds)
The turbTimeTweet() subsets the gageResults() output for turbidity metrics. For these metrics to trigger a notification, there must be turbidity measures sustained above the numeric or percent threshold (see Turbidity above for more information on when each threshold is implemented) or above the gage's 99th percentile threshold for at least 30 minutes. The 30 minute window is verified and any 30 minute windows noting 3 or more NA's (more than 40% of the data missing) are discounted prior to sending a tweet. After removing invalid windows of data, any flags of turbidity above the appropriate threshold sustained for at least 30 minutes sends a tweet. These notifications are triggered by valid upstream or downstream flags and by valid upstream/downstream flagged comparisons.

If a notification is necessary, the function establishes the appropriate stream name, parameter notification, and UID and necessary inputs to the NWIS server to link to a page that graphs the appropriate gage(s), parameter, and data window. A plot of the turbidity data and associated gage height (from nearest gage) is presented for at least the last 24 hours to give context to the flagged turbidity data. The two hour window that breaks the threshold is specifically highlighted on the plot send with the tweet. Additionally, the function saves a copy of the gageResults(), plot, and raw data responisble for sending the notification in a flat file. The UID from the tweet can be matched to the flat file name and plot name if any review  of raw data or analysis is required at a later point in time. 

Turbidity tweeting helper functions for data manipulation and seamless plotting.
```{r}
dataManipulationForTurbTweets_2hr <- function(upstreamData,downstreamData,turbidity99th1,turbidity99th2){
  if(unique(c('Turb_Inst',"Turb_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,'Turb_Inst')%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
    # If gage height data available at gage then grab that, too
    if("GH_Inst" %in% names(upstreamData)){
      if(unique(upstreamData$site_no)[!is.na(unique(upstreamData$site_no))]=="0205450393"){
        gh <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,GH_Inst)%>%
          mutate(site_noGH='02054500')%>% dplyr::select(agency_cd,site_noGH,everything(),-site_no)
      }else{
        gh <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,GH_Inst)%>%
          rename(site_noGH=!!names(.[2]))}
      
    }else{gh <- dplyr::select(upstreamData,agency_cd,dateTime)%>%
      mutate(site_noGH=NA,GH_Inst=NA)%>%dplyr::select(agency_cd,site_noGH,dateTime,GH_Inst)}
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('Turb_Inst',"Turb_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,'Turb_Inst')%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
    # If gage height data available at gage then grab that, too
    if("GH_Inst" %in% names(downstreamData)){
      gh <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,GH_Inst) %>%
        rename(site_noGH=!!names(.[2]))
    }else{
      if(unique(upstreamData$site_no)[!is.na(unique(upstreamData$site_no))]=="0205450393"){
        gh <- gh}
      if(exists('gh')){gh <- gh}else{
        gh <- dplyr::select(downstreamData,agency_cd,dateTime)%>%
          mutate(site_noGH=NA,GH_Inst=NA)%>%dplyr::select(agency_cd,site_noGH,dateTime,GH_Inst)}}
    
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime'))%>%
    full_join(gh,by=c('agency_cd','dateTime')) %>%
    mutate(turbidity99th1=turbidity99th1,turbidity99th2=turbidity99th2)
  return(together)
}


dataManipulationForTurbTweets_2days <- function(upstreamData,downstreamData,turbidity99th1,turbidity99th2){
  if(unique(c('Turb_Inst',"Turb_Inst_cd") %in% names(upstreamData))){
    UP <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,'Turb_Inst')%>%rename(upstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
    # If gage height data available at gage then grab that, too
    if("GH_Inst" %in% names(upstreamData)){
      if(unique(upstreamData$site_no)[!is.na(unique(upstreamData$site_no))]=="0205450393"){
        gh <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,GH_Inst)%>%
          mutate(site_noGH='02054500')%>% dplyr::select(agency_cd,site_noGH,everything(),-site_no)
      }else{
        gh <- dplyr::select(upstreamData,agency_cd,site_no,dateTime,GH_Inst)%>%
          rename(site_noGH=!!names(.[2]))}
      
    }else{gh <- dplyr::select(upstreamData,agency_cd,dateTime)%>%
      mutate(site_noGH=NA,GH_Inst=NA)%>%dplyr::select(agency_cd,site_noGH,dateTime,GH_Inst)}
  }else{UP <- select(upstreamData,agency_cd,site_no,dateTime)%>%mutate(upstream=NA)}
  if(unique(c('Turb_Inst',"Turb_Inst_cd") %in% names(downstreamData))){
    DOWN <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,'Turb_Inst')%>%rename(downstream=!!names(.[4])) # change parameter to general name to make further manipulations easier
    # If gage height data available at gage then grab that, too
    if("GH_Inst" %in% names(downstreamData)){
      gh <- dplyr::select(downstreamData,agency_cd,site_no,dateTime,GH_Inst) %>%
        rename(site_noGH=!!names(.[2]))
    }else{
      if(unique(upstreamData$site_no)[!is.na(unique(upstreamData$site_no))]=="0205450393"){
        gh <- gh}
      if(exists('gh')){gh <- gh}else{
        gh <- dplyr::select(downstreamData,agency_cd,dateTime)%>%
          mutate(site_noGH=NA,GH_Inst=NA)%>%dplyr::select(agency_cd,site_noGH,dateTime,GH_Inst)}}
    
  }else{DOWN <- select(downstreamData,agency_cd,site_no,dateTime)%>%mutate(downstream=NA)}
  
  
  together <- full_join(UP,DOWN,by=c('agency_cd','dateTime'))%>%
    full_join(gh,by=c('agency_cd','dateTime')) %>%
    mutate(turbidity99th1=turbidity99th1,turbidity99th2=turbidity99th2)
  return(together)
}

pairedTurbidityPlot_2days <- function(turbidityData,turbidity99th1,turbidity99th2){
  if(unique(turbidityData$site_noGH)[!is.na(unique(turbidityData$site_noGH))] ==
     unique(turbidityData$site_no.x)[!is.na(unique(turbidityData$site_no.x))]){updown <- "Upstream"}
  if(unique(turbidityData$site_noGH)[!is.na(unique(turbidityData$site_noGH))] ==
     unique(turbidityData$site_no.y)[!is.na(unique(turbidityData$site_no.y))]){updown <- "Downstream"}
  if(unique(turbidityData$site_noGH)[!is.na(unique(turbidityData$site_noGH))] == "02054500"){
    updown <- 'Lafayette'}
  
  up <- dplyr::select(turbidityData,dateTime,upstream)%>%
    gather(gage,measure,upstream)%>%mutate(Turbidity99=turbidity99th1,panel=2)#'Upstream Turbidity (NTU)')
  down <- dplyr::select(turbidityData,dateTime,downstream)%>%
    gather(gage,measure,downstream)%>%mutate(Turbidity99=turbidity99th2,panel=3)#'Downstream Turbidity (NTU)')
  gh <- dplyr::select(turbidityData,dateTime,GH_Inst)%>%
    rename(measure=GH_Inst)%>% mutate(gage=updown,Turbidity99=NA,panel=1)%>% select(dateTime,gage,Turbidity99,measure,panel)#paste(updown,'Gage Height (ft)',sep=' ')) 
  dat <- rbind(up,down,gh)
  dat2 <- dplyr::filter(dat,dateTime >= last2Hours & panel==2) %>%
    mutate(a=min(dateTime),b=max(dateTime),c=min(measure,na.rm=T),
           d=max(max(measure,na.rm=T),max(Turbidity99)))
  dat3 <- dplyr::filter(dat,dateTime >= last2Hours & panel==3) %>%
    mutate(a=min(dateTime),b=max(dateTime),c=min(measure,na.rm=T),
           d=max(max(measure,na.rm=T),max(Turbidity99)))
  correctName <- c(`1`=paste(updown,'Gage Height (ft)',sep=' '),
                   `2`='Upstream Turbidity (NTU)',`3`='Downstream Turbidity (NTU)')
  
  
  plot3_alldata2hr <- ggplot(dat,mapping = aes(x=dateTime,y=measure))+
    facet_grid(panel~.,scale='free',labeller = as_labeller(correctName))+
    geom_rect(data=dat2,aes(xmin=a,xmax=b,ymin=c,ymax=d,fill=TRUE),
              alpha=0.2)+
    geom_rect(data=dat3,aes(xmin=a,xmax=b,ymin=c,ymax=d,fill=TRUE),
              alpha=0.2)+
    
    geom_point(data=up,stat = 'identity',colour='coral')+
    geom_line(data=up,aes(dateTime,Turbidity99),colour='red')+
    
    geom_point(data=down,stat = 'identity',colour='blueviolet')+
    geom_line(data=down,aes(dateTime,Turbidity99),colour='blue')+
    geom_point(data=gh,stat = 'identity',colour='gray') +
    
    
    scale_fill_manual(values='gray')+guides(fill=F)
  return(plot3_alldata2hr)
}


upstreamTurbidityPlot2day <- function(turbidityData,turbidity99th1){
  if(unique(turbidityData$site_noGH)[!is.na(unique(turbidityData$site_noGH))] ==
     unique(turbidityData$site_no.x)[!is.na(unique(turbidityData$site_no.x))]){updown <- "Upstream"}
  if(unique(turbidityData$site_noGH)[!is.na(unique(turbidityData$site_noGH))] ==
     unique(turbidityData$site_no.y)[!is.na(unique(turbidityData$site_no.y))]){updown <- "Downstream"}
  if(unique(turbidityData$site_noGH)[!is.na(unique(turbidityData$site_noGH))] == "02054500"){
    updown <- 'Lafayette'}
  
  up <- dplyr::select(turbidityData,dateTime,upstream)%>%
    gather(gage,measure,upstream)%>%mutate(Turbidity99=turbidity99th1,panel=2)#'Upstream Turbidity (NTU)')
  gh <- dplyr::select(turbidityData,dateTime,GH_Inst)%>%
    rename(measure=GH_Inst)%>% mutate(gage=updown,Turbidity99=NA,panel=1)%>% select(dateTime,gage,Turbidity99,measure,panel)#paste(updown,'Gage Height (ft)',sep=' ')) 
  dat <- rbind(up,gh)
  dat2 <- dplyr::filter(dat,dateTime >= last2Hours & panel==2) %>%
    mutate(a=min(dateTime),b=max(dateTime),c=min(measure,na.rm=T),
           d=max(max(measure,na.rm=T),max(Turbidity99)))
  correctName <- c(`1`=paste(updown,'Gage Height (ft)',sep=' '),
                   `2`='Upstream Turbidity (NTU)')
  
  upstream2dayplot <- ggplot(dat,mapping = aes(x=dateTime,y=measure))+
    facet_grid(panel~.,scale='free',labeller = as_labeller(correctName))+
    geom_rect(data=dat2,aes(xmin=a,xmax=b,ymin=c,ymax=d,fill=TRUE),
              alpha=0.2)+
    geom_point(data=up,stat = 'identity',colour='coral')+
    geom_line(data=up,aes(dateTime,Turbidity99),colour='red')+
    geom_point(data=gh,stat = 'identity',colour='gray') +
    scale_fill_manual(values='gray')+guides(fill=F)
  return(upstream2dayplot)
}


downstreamTurbidityPlot2day <- function(turbidityData,turbidity99th2){
  if(unique(turbidityData$site_noGH)[!is.na(unique(turbidityData$site_noGH))] ==
     unique(turbidityData$site_no.x)[!is.na(unique(turbidityData$site_no.x))]){updown <- "Upstream"}
  if(unique(turbidityData$site_noGH)[!is.na(unique(turbidityData$site_noGH))] ==
     unique(turbidityData$site_no.y)[!is.na(unique(turbidityData$site_no.y))]){updown <- "Downstream"}
  if(unique(turbidityData$site_noGH)[!is.na(unique(turbidityData$site_noGH))] == "02054500"){
    updown <- 'Lafayette'}
  
  down <- dplyr::select(turbidityData,dateTime,downstream)%>%
    gather(gage,measure,downstream)%>%mutate(Turbidity99=turbidity99th2,panel=3)#'Downstream Turbidity (NTU)')
  gh <- dplyr::select(turbidityData,dateTime,GH_Inst)%>%
    rename(measure=GH_Inst)%>% mutate(gage=updown,Turbidity99=NA,panel=1)%>% select(dateTime,gage,Turbidity99,measure,panel)#paste(updown,'Gage Height (ft)',sep=' ')) 
  dat <- rbind(down,gh)
  dat3 <- dplyr::filter(dat,dateTime >= last2Hours & panel==3) %>%
    mutate(a=min(dateTime),b=max(dateTime),c=min(measure,na.rm=T),
           d=max(max(measure,na.rm=T),max(Turbidity99)))
  correctName <- c(`1`=paste(updown,'Gage Height (ft)',sep=' '),`3`='Downstream Turbidity (NTU)')
  
  
  downstream2dayplot <- ggplot(dat,mapping = aes(x=dateTime,y=measure))+
    facet_grid(panel~.,scale='free',labeller = as_labeller(correctName))+
    geom_rect(data=dat3,aes(xmin=a,xmax=b,ymin=c,ymax=d,fill=TRUE),
              alpha=0.2)+
    geom_point(data=down,stat = 'identity',colour='blueviolet')+
    geom_line(data=down,aes(dateTime,Turbidity99),colour='blue')+
    geom_point(data=gh,stat = 'identity',colour='gray') +
    scale_fill_manual(values='gray')+guides(fill=F)
  return(downstream2dayplot)
}
```
Turbidity tweeting function
```{r}
# Turbidity tweet
turbTimeTweet <- function(gageResults,upstreamData,downstreamData,turbidity99th1,turbidity99th2,
                          upstreamDataForTurbidity,downstreamDataForTurbidity){
  turbTimeData <- select(gageResults,dateTime,site_no.x,site_no.y,site_noGH,GH_Inst,WQSapplied,turbidity_valid30minuteWindow,
                         turbidity_NAs,turbidity_ExceedanceType,turbidity_Exceedance,
                         turbidity_upstreamExceed99th,turbidity_upstreamNAs,
                         turbidity_downstreamExceed99th,turbidity_downstreamNAs)
  
  # Only use data from correct 1hr window
  validData <- filter(turbTimeData,turbidity_valid30minuteWindow==30)
  
  # upstream downstream change comparison
  if(nrow(validData)>0){
    validComparison <- filter(validData,turbidity_Exceedance>0, # Limit dataset to only violations
                              turbidity_NAs <= 3) # Only allow up to 3 missing turbidity reading per hour for any hour to count toward max change rate violation
    
    # Data manipulation for plots
    together <- dataManipulationForTurbTweets_2hr(upstreamData,downstreamData,turbidity99th1,turbidity99th2)
    together2days <- dataManipulationForTurbTweets_2days(upstreamDataForTurbidity,downstreamDataForTurbidity,turbidity99th1,turbidity99th2)
    
    if(nrow(validComparison)>0){
      uniqueTweetIdentifier <- format(as.numeric(Sys.time()),nsmall=4) # Tweet function will not work if the status is the same as a previous status
      PCcolName <- 'turbidity_upstreamDownstreamDataReview'
      date1 <- as.Date(validData$dateTime[1])-3 # Need to hardwire date into link so get same results well after original notification
      date2 <- as.Date(validData$dateTime[1]) # Need to hardwire date into link so get same results well after original notification
      gageNumber1 <- unique(validData$site_no.x)[!is.na(unique(validData$site_no.x))]
      gageNumber2 <- unique(validData$site_no.y)[!is.na(unique(validData$site_no.y))]
      streamName <- gageInfo[grep(as.numeric(gageNumber1),gageInfo$`USGS Station ID`),]$`Stream Name`[1]
      weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                       '&cb_63680=on&site_no=',gageNumber1,'%2C',gageNumber2,'&format=gif_mult_sites',sep='')
      file_name <- paste('notifications/images/',uniqueTweetIdentifier,'.jpg',sep='')
      jpeg(file_name)
      print(pairedTurbidityPlot_2days(together2days,turbidity99th1,turbidity99th2))
      dev.off()
      
      tweet(paste(streamName,PCcolName,weblink,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T,
            mediaPath=paste('notifications/images/',uniqueTweetIdentifier,'.jpg',sep=''))
      # Save a record of the data that caused the tweet, indexed by uniqueTweetIdentifier
      write.csv(together,paste('notifications/',uniqueTweetIdentifier,'.csv',sep=""),row.names = F)
    }
    
    # Upstream absolute threshold Analysis
    validUP <- filter(validData,turbidity_upstreamExceed99th>0, # Limit dataset to only violations
                      turbidity_upstreamNAs <=3) # Only allow up to 3 missing turbidity reading per hour for any hour to count toward max change rate violation
    # Only send tweet if at least 1 valid row (1 hr violation) & <= 3 missing turbidity readings within hour
    if(nrow(validUP)>0){
      uniqueTweetIdentifier <- format(as.numeric(Sys.time()),nsmall=4) # Tweet function will not work if the status is the same as a previous status
      PCcolName <- 'turbidity_upstreamExceed99th'
      gageNumber <- unique(validData$site_no.x)[!is.na(unique(validData$site_no.x))]
      streamName <- gageInfo[grep(as.numeric(gageNumber),gageInfo$`USGS Station ID`),]$`Stream Name`[1]
      date1 <- as.Date(validData$dateTime[1])-3 # Need to hardwire date into link so get same results well after original notification
      date2 <- as.Date(validData$dateTime[1]) # Need to hardwire date into link so get same results well after original notification
      weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                       '&cb_63680=on&site_no=',gageNumber,sep = "")
      file_name <- paste('notifications/images/',uniqueTweetIdentifier,'.jpg',sep='')
      jpeg(file_name)
      print(upstreamTurbidityPlot2day(together2days,turbidity99th1))
      dev.off()
      tweet(paste(streamName,PCcolName,weblink,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T,
            mediaPath=paste('notifications/images/',uniqueTweetIdentifier,'.jpg',sep=''))
      # Save a record of the data that caused the tweet, indexed by uniqueTweetIdentifier
      datToSave <- turbTimeData[,c(1,2,7,11,12)]
      upstreamRAW <- dplyr::select(together,-c(site_no.y,downstream))
      datToSave <- plyr::join_all(list(datToSave,upstreamRAW),by='dateTime')
      write.csv(datToSave,paste('notifications/',uniqueTweetIdentifier,'.csv',sep=""),row.names = F)
    }
    # Downstream Analysis
    validDOWN <- filter(validData,turbidity_downstreamExceed99th>0, # Limit dataset to only violations
                        turbidity_downstreamNAs <=3) # Only allow up to 3 missing turbidity reading per hour for any hour to count toward max change rate violation
    # Only send tweet if at least 1 valid row (1 hr violation) & <= 4 missing turbidity readings within hour
    if(nrow(validDOWN)>0){
      uniqueTweetIdentifier <- format(as.numeric(Sys.time()),nsmall=4) # Tweet function will not work if the status is the same as a previous status
      PCcolName <- 'turbidity_downstreamExceed99th'
      gageNumber <- unique(validData$site_no.x)[!is.na(unique(validData$site_no.x))]
      streamName <- gageInfo[grep(as.numeric(gageNumber),gageInfo$`USGS Station ID`),]$`Stream Name`[1]
      date1 <- as.Date(validData$dateTime[1])-3 # Need to hardwire date into link so get same results well after original notification
      date2 <- as.Date(validData$dateTime[1]) # Need to hardwire date into link so get same results well after original notification
      weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                       '&cb_63680=on&site_no=',gageNumber,sep = "")
      file_name <- paste('notifications/images/',uniqueTweetIdentifier,'.jpg',sep='')
      jpeg(file_name)
      print(downstreamTurbidityPlot2day(together2days,turbidity99th2))
      dev.off()
      tweet(paste(streamName,PCcolName,weblink,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T,
            mediaPath=paste('notifications/images/',uniqueTweetIdentifier,'.jpg',sep=''))
      # Save a record of the data that caused the tweet, indexed by uniqueTweetIdentifier
      datToSave <- turbTimeData[,c(1,3,7,13,14)]
      downstreamRAW <- dplyr::select(together,-c(site_no.x,upstream))
      datToSave <- plyr::join_all(list(datToSave,downstreamRAW),by='dateTime')
      write.csv(datToSave,paste('notifications/',uniqueTweetIdentifier,'.csv',sep=""),row.names = F)}
  }
}
```


#### Tweet if no data is received from gage or gage pairs during a data pull 

The noGageDataTweet() notifies authorized Twitter users when a gage or pair of gages does not send any data to the NWIS server for a particular data pull. By notifying the users when gages are not pushing data to the NWIS server for a particular time  period, DEQ  staff can notify USGS data managers of gage malfuntions or potential foul play. 

The gageResults() will output very limited information if one or both of the gages have not produced data in the specified window. If no gage is retrieved for either or both gages, the noGageDataTweet() determines which stream and which gage(s) did not produce data, identifies the time period where the data is missing, and constructs a weblink (or weblinks) to the NWIS server highlighting when the problem occurred. Additionally, the function saves a copy of the gageResults() and any raw data responisble for sending the notification in a flat file. The UID from the tweet can be matched to the flat file name if any review  of raw data or analysis is required at a later point in time. 

```{r}
# Send Notification if no data could be compared upstream/downstream for pull
noGageDataTweet <- function(gageResults,i,last2Hours){
  if(nrow(filter(gageResults,!is.na(site_no.x))) == 0 | nrow(filter(gageResults,!is.na(site_no.y))) == 0){
    uniqueTweetIdentifier <- format(as.numeric(Sys.time()),nsmall=4) # Tweet function will not work if the status is the same as a previous status
    date1 <- as.Date(last2Hours)-3 # Need to hardwire date into link so get same results well after original notification
    date2 <- as.Date(last2Hours) # Need to hardwire date into link so get same results well after original notification
    parameterCode <- '&cb_00010=on&cb_00095=on&cb_00300=on&cb_00400=on&cb_63680=on'
    
    # find Culprit
    if(nrow(filter(gageResults,!is.na(site_no.x))) == 0){
      columnName <- 'upstreamNoData'
      gageNumberMissing <- paste(0,gageInfo$`USGS Station ID`[i],sep = "")
      streamName <- gageInfo$`Stream Name`[i]}
    if(nrow(filter(gageResults,!is.na(site_no.y))) == 0){
      columnName <- 'downstreamNoData'
      gageNumberMissing <- paste(0,gageInfo$`USGS Station ID`[i+1],sep = "")
      streamName <- gageInfo$`Stream Name`[i]}
    if(nrow(filter(gageResults,!is.na(site_no.x))) == 0 &
       nrow(filter(gageResults,!is.na(site_no.y))) == 0){columnName <- 'NoData'}
    # If both gages are missing, give special tweet
    if(columnName=='NoData'){
      streamName <- gageInfo$`Stream Name`[i]
      gageNumberMissing1 <- paste(0,gageInfo$`USGS Station ID`[i],sep="")
      gageNumberMissing2 <- paste(0,gageInfo$`USGS Station ID`[i+1],sep = "")
      weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                       parameterCode,'&site_no=',gageNumberMissing1,sep = "")
      weblink2 <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                        parameterCode,'&site_no=',gageNumberMissing2,sep = "")
      tweet(paste(streamName,columnName,weblink," & ",weblink2,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T)
      # fix gageResults so we know which gages blank data associated with
      gageResults$site_no.x <- gageNumberMissing1
      gageResults$site_no.y <- gageNumberMissing2
      }else{weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                       parameterCode,'&site_no=',gageNumberMissing,sep = "")}
    
    tweet(paste(streamName,columnName,weblink,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T)
    
    # Save a record of the data that caused the tweet, indexed by uniqueTweetIdentifier
    write.csv(gageResults,paste('notifications/',uniqueTweetIdentifier,'.csv',sep=""),row.names = F)}
}
```

#### Tweet if no turbidity data is received from gage or gage pairs during a data pull 

The noTurbidityDataTweet() notifies authorized Twitter users when a gage or pair of gages does not send any turbidity data to the NWIS server for a particular data pull. By notifying the users when gages are not pushing turbidity data to the NWIS server for a particular time  period, DEQ  staff can notify USGS data managers of gage malfuntions or potential foul play. 

The gageResults() will output very limited information if one or both of the gages have not produced data in the specified window. If no gage is retrieved for either or both gages, the noGageDataTweet() determines which stream and which gage(s) did not produce data, identifies the time period where the data is missing, and constructs a weblink (or weblinks) to the NWIS server highlighting when the problem occurred. Additionally, the function saves a copy of the gageResults() and any raw data responisble for sending the notification in a flat file. The UID from the tweet can be matched to the flat file name if any review  of raw data or analysis is required at a later point in time. 

```{r}
# Send Notification if no turbidity data received
noTurbidityDataTweet <- function(gageResults,i,last2Hours){
  turbidityData <- dplyr::select(gageResults,agency_cd,dateTime,site_no.x,site_no.y,site_noGH,GH_Inst,
                                 turbidity_valid30minuteWindow,turbidity_NAs,turbidity_ExceedanceType,
                                 turbidity_Exceedance,turbidity_upstreamExceed99th,turbidity_upstreamNAs,
                                 turbidity_downstreamExceed99th,turbidity_downstreamNAs)
  
  
  
  if(nrow(filter(turbidityData,!is.na(site_no.x))) == 0 | nrow(filter(turbidityData,!is.na(site_no.y))) == 0){
    uniqueTweetIdentifier <- format(as.numeric(Sys.time()),nsmall=4) # Tweet function will not work if the status is the same as a previous status
    date1 <- as.Date(last2Hours)-3 # Need to hardwire date into link so get same results well after original notification
    date2 <- as.Date(last2Hours) # Need to hardwire date into link so get same results well after original notification
    parameterCode <- '&cb_63680=on'
    
    # find Culprit
    if(nrow(filter(gageResults,!is.na(site_no.x))) == 0){
      columnName <- 'upstreamNoTurbidityData'
      gageNumberMissing <- paste(0,gageInfo$`USGS Station ID`[i],sep = "")
      streamName <- gageInfo$`Stream Name`[i]}
    if(nrow(filter(gageResults,!is.na(site_no.y))) == 0){
      columnName <- 'downstreamNoTurbidityData'
      gageNumberMissing <- paste(0,gageInfo$`USGS Station ID`[i+1],sep = "")
      streamName <- gageInfo$`Stream Name`[i]}
    if(nrow(filter(gageResults,!is.na(site_no.x))) == 0 &
       nrow(filter(gageResults,!is.na(site_no.y))) == 0){columnName <- 'NoTurbidityData'}
    # If both gages are missing, give special tweet
    if(columnName=='NoData'){
      streamName <- gageInfo$`Stream Name`[i]
      gageNumberMissing1 <- paste(0,gageInfo$`USGS Station ID`[i],sep="")
      gageNumberMissing2 <- paste(0,gageInfo$`USGS Station ID`[i+1],sep = "")
      weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                       parameterCode,'&site_no=',gageNumberMissing1,sep = "")
      weblink2 <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                        parameterCode,'&site_no=',gageNumberMissing2,sep = "")
      tweet(paste(streamName,columnName,weblink," & ",weblink2,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T)
      # fix gageResults so we know which gages blank data associated with
      gageResults$site_no.x <- gageNumberMissing1
      gageResults$site_no.y <- gageNumberMissing2
    }else{weblink <- paste('waterdata.usgs.gov/va/nwis/uv?period=&begin_date=',date1,'&end_date=',date2,
                           parameterCode,'&site_no=',gageNumberMissing,sep = "")}
    
    tweet(paste(streamName,columnName,weblink,'UID:',uniqueTweetIdentifier,sep=" "),bypassCharLimit=T)
    
    # Save a record of the data that caused the tweet, indexed by uniqueTweetIdentifier
    write.csv(gageResults,paste('notifications/',uniqueTweetIdentifier,'.csv',sep=""),row.names = F)}
}
```

